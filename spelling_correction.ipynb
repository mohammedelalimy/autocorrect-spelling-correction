{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d25b9a7726b947f59f7b350dad3c15c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fa6af60aa8e4499fae6317fae3c50d23",
              "IPY_MODEL_a12db16086a54e77afeba35ec47cc94d",
              "IPY_MODEL_32a97647e2fc4f3ea0da79212f635fb7",
              "IPY_MODEL_d11f6ad4735541859cbc54dc758d0617"
            ],
            "layout": "IPY_MODEL_d6091c1a8f9e41dea0c18725c044f61f"
          }
        },
        "5f2f899da2ff4adbb707678ec53c48bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9e8dcf59b4443b1ab70202917dd8cb3",
            "placeholder": "​",
            "style": "IPY_MODEL_3cad1abc33984a2f8981a15d607673bd",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "ef40607288114d4b858197b888101010": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_8ac3a6a55da846f9b82bff5ad5785c89",
            "placeholder": "​",
            "style": "IPY_MODEL_65750e9ea21149dc852ff87270b289ad",
            "value": ""
          }
        },
        "a00b7daf426946f39ae8963067ff7c4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_c40d3e151e5047799f20a82c78917190",
            "style": "IPY_MODEL_ed531e03af9647eda148558c51b7c502",
            "value": true
          }
        },
        "19c3c7197f5648b9bc687d5ce730d47d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_8c4dc26ab85347cf981b64db0dd1c265",
            "style": "IPY_MODEL_53f05e89538548a8b02df80c06f9c936",
            "tooltip": ""
          }
        },
        "5d628ba5c86f4c1ea8ae17946faa3eb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fff90ae9cbd4432d8d9616f793d72cdd",
            "placeholder": "​",
            "style": "IPY_MODEL_47c65ddfcd3b4ea1bea3c8c766bf071b",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "d6091c1a8f9e41dea0c18725c044f61f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "e9e8dcf59b4443b1ab70202917dd8cb3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3cad1abc33984a2f8981a15d607673bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ac3a6a55da846f9b82bff5ad5785c89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65750e9ea21149dc852ff87270b289ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c40d3e151e5047799f20a82c78917190": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed531e03af9647eda148558c51b7c502": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c4dc26ab85347cf981b64db0dd1c265": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53f05e89538548a8b02df80c06f9c936": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "fff90ae9cbd4432d8d9616f793d72cdd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47c65ddfcd3b4ea1bea3c8c766bf071b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7661ab9caeea4ba880bd38171abfbad1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da6cb343da4d44259e6d1a19c8fada73",
            "placeholder": "​",
            "style": "IPY_MODEL_331542720ed143bab3c88b2853a2a2d7",
            "value": "Connecting..."
          }
        },
        "da6cb343da4d44259e6d1a19c8fada73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "331542720ed143bab3c88b2853a2a2d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa6af60aa8e4499fae6317fae3c50d23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0786bd5639a4734bcbe397c5e324d54",
            "placeholder": "​",
            "style": "IPY_MODEL_6fc53aa0b97c4f378e8638570e8c9845",
            "value": "Token is valid (permission: write)."
          }
        },
        "a12db16086a54e77afeba35ec47cc94d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d55b683fea114661aef8d2550babddb4",
            "placeholder": "​",
            "style": "IPY_MODEL_9b2fffeccdd440f2b1ba6906f4635edf",
            "value": "Your token has been saved in your configured git credential helpers (store)."
          }
        },
        "32a97647e2fc4f3ea0da79212f635fb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74da0b79a5d44aeab35cb3f48ae231e6",
            "placeholder": "​",
            "style": "IPY_MODEL_8bc3b53341c348fca0592017904e390e",
            "value": "Your token has been saved to /root/.cache/huggingface/token"
          }
        },
        "d11f6ad4735541859cbc54dc758d0617": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1740583a97140ee8094b580ed7bfbb8",
            "placeholder": "​",
            "style": "IPY_MODEL_735003783cae4389af10e959338b976d",
            "value": "Login successful"
          }
        },
        "b0786bd5639a4734bcbe397c5e324d54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fc53aa0b97c4f378e8638570e8c9845": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d55b683fea114661aef8d2550babddb4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b2fffeccdd440f2b1ba6906f4635edf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "74da0b79a5d44aeab35cb3f48ae231e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8bc3b53341c348fca0592017904e390e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f1740583a97140ee8094b580ed7bfbb8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "735003783cae4389af10e959338b976d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "18f1a5e9a31e4b4c9d835bf96899c38f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e280f109f8d3478f92e91f23cc8f668d",
              "IPY_MODEL_aa41ce9b9e514b01be08ad864d56b8f8",
              "IPY_MODEL_480e70de3645430d9957807bc0a64789"
            ],
            "layout": "IPY_MODEL_11fcd25f9b45490dabdc8e9b889ff511"
          }
        },
        "e280f109f8d3478f92e91f23cc8f668d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6224ee2ab1194e9f936656417ba48f65",
            "placeholder": "​",
            "style": "IPY_MODEL_074dab0f43984fb59a761d0d48f93e19",
            "value": "model.safetensors: 100%"
          }
        },
        "aa41ce9b9e514b01be08ad864d56b8f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3497e925c7b3417d9d8f15eb5ef1c28b",
            "max": 557912620,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d17ea8fa6a9147ae8f49faa39d7746bd",
            "value": 557912620
          }
        },
        "480e70de3645430d9957807bc0a64789": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_882966b68dba469d84d77ccc5bbc490d",
            "placeholder": "​",
            "style": "IPY_MODEL_d40f90da4e2e41e1aeb3adce4b5ee36d",
            "value": " 558M/558M [00:39&lt;00:00, 6.87MB/s]"
          }
        },
        "11fcd25f9b45490dabdc8e9b889ff511": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6224ee2ab1194e9f936656417ba48f65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "074dab0f43984fb59a761d0d48f93e19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3497e925c7b3417d9d8f15eb5ef1c28b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d17ea8fa6a9147ae8f49faa39d7746bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "882966b68dba469d84d77ccc5bbc490d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d40f90da4e2e41e1aeb3adce4b5ee36d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ilD9Xy93kFtB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f016778d-159c-4b48-8228-f1a7ece51b38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "70000 data/data.txt\n"
          ]
        }
      ],
      "source": [
        "!cut -f 2 data/text_data.txt > data/tmp.txt\n",
        "!shuf data/tmp.txt > data/data.txt\n",
        "!rm data/tmp.txt\n",
        "!wc -l data/data.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python generate_dataset.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOVFzkGo2Kzq",
        "outputId": "571717b0-662c-46bb-aac1-ee0e10c468ee"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "config.json: 100% 1.72k/1.72k [00:00<00:00, 7.47MB/s]\n",
            "vocab.json: 100% 899k/899k [00:00<00:00, 3.65MB/s]\n",
            "merges.txt: 100% 456k/456k [00:00<00:00, 51.6MB/s]\n",
            "tokenizer.json: 100% 1.36M/1.36M [00:00<00:00, 5.48MB/s]\n",
            "  1% 573/70000 [00:00<01:21, 852.47it/s]skipping line as its too long (8451):\n",
            "This is my feedback as a Beta-Tester for the courseWeek 1I thought that the videos were clear, well organized and flowed well from topic to topic. There was a clear logic as the professor developed the various ratios.What was missing for me was some in-line quizzes. Not the tell me what I just told you type but rather ones that make you think. So, for example, in the final video for Week 1, the optional video, instead of just suggesting that the students play with the spreadsheet, I think it would be better to give them an actual task or two change the assumption about X to this value. What is the impact on the Y ratio? Why? I liked that he showed what numbers needed to be changed to make the share valuation closer to $55. But rather than just telling us the answer, this would be another opportunity to have the students stop the video and go try it themselves. With a specific task, it is likely that more students will go and work with the spreadsheet. This is where the real learning takes place.One of the things that I really liked about the design of prior courses by Professor Bushee was the fact that he had examples throughout the videos that had you apply the information right away. But, perhaps this is just me. I know that I learn a lot better by doing rather than just watching the videos and going yeah that makes sense. I understand I also recognize that some students, in past courses, have probably said they don’t find the in-line quizzes valuable. But, is that a reflection of the value of in-line quizzes as a whole or just in-line quizzes that simply require parroting something said in the video.I’m sure that the professor can come up with lots of examples. In Week 1 Video 1 the in-line quiz might provide some numbers for De-levered Net Income, Sales, Average Total Assets and Average Shareholder’s Equity and asking for the results of each of the ratios in the Dupont Analysis. And maybe a think about what this means type question that is not necessarily marked but for which an answer is provided in the video. Alternatively, he could have the students change some specific things in the Woof Junction spreadsheet and indicate what impact that has on the ratios and why.Week 1 Video 2 offers lots of similar opportunities with the Profitability and Turnover Ratios. Perhaps requiring the students to work backwards from a specific ratio to determine gross profit would be effective. Or, perhaps a question that relates strategy specifically to the ratios. For example, what would happen to the Gross Margin if Woof introduced a credit card and days receivable increased to 31.6 in 2015? Just something to engage people with the materials.All of the videos offer similar opportunities and I think having specific problems or questions will enhance the learning experience rather than just suggesting that they go look at the spreadsheet. The audience for these courses tends to be quite a bit different from your average upper tier university student and probably needs a bit more hand holding and direction in order to be successful.Also, if Professor Bushee expects students will watch the optional videos anyway, why make them optional? In the case of the Valuation Video, despite some of the mathematics being a little scary for some students, I think that the information there is really useful and helps to solidify an understanding of the spreadsheet.I’m wondering if an in-quiz question would be helpful. Perhaps it might provide a new set of financials for Woof Junction and ask for ratio calculation and what that means in terms of their position in the marketplace or something similar. Just some practice questions to get people working with the information.Same comments basically apply for the remainder of the weeks. I think that it would help the students to have some in-line quizzes  this not only breaks up the longer videos and helps to keep students focused but also provides a reinforcement of key concepts.I really liked the quiz for Week 1 even though I struggled with the questions where there are multiple correct responses. The quiz effectively reinforces the information covered very well and requires one to think about what was covered in the lectures.You may want to remind students that the questions may change from quiz to quiz. In many of these on-demand courses, the quiz questions do not change and students may be in the habit of not rereading the questions they have gotten correct on previous attempts.Week 2  Revenue After Cash Collection at 739  talking about Days Unearned Revenue and mentions that an increase means slower future recognition. A bit more explanation around what that means would be useful.Week 3  no particular additional comments on the lectures other than some in-line questions might be good.. I found Benford’s Law really interesting.Week 4. It would be really nice to have something to break up the lectures  some in-line quiz questions might help. This would also help to reinforce the material.Week 4 quiz Question 9 -, the double negative wording of the question and the correct response may cause confusion for students  particularly for those for whom English is not their native language.Overall CommentsI enjoyed the course and learned a lot. I was wondering whether it would be possible to provide a summary document with all the key information from each week related to the ratio calculations and the key things to look for related to those ratios. I know that the ratios are provided in the spreadsheet but it might be good to have a written summary with some supplemental information about how to use the ratios.I think in-line quizzes or practice questions would be helpful for students  perhaps ones that asked students to do specific things in the spreadsheet and come back with an answer. They don’t need to be long or complicated  just something that gets people into the spreadsheets and working with them early. You may want to do something stronger to encourage them to play with the spreadsheet. Many will feel reluctant to change the numbers in the spreadsheet for fear of messing it up. Perhaps a reminder that they can change whatever they want because if they mess something up they can always download it again. Or they can save a copy and play in that leaving the original untouched.It also might be a good idea to have a playground sheet where there is a simple set of Financial Statements and the students can try changing things in the financial statements and see the impact on the key ratios without having to move from one spreadsheet to another  so, a combination of the Original tab and the first two columns of the Ratios tab. You might even want to have two columns for the ratios  one for the ratios with the original numbers that does not change (fixed values) and one for the changed numbers, so students can see the effect of the changes easily.In terms of the spreadsheets, I thought that the Original, the Ratios and the CommonSize tabs were fairly straight forward and relatively easy to understand. That may not be the case for people less familiar with MS-EXCEL but I don’t know what the target audience is for this course so the students may all be proficient with the tool. On the Valuation tab, I was wondering if the numbers in Row 41 should be highlighted in some way to emphasize that they are Years. That is not clear on first glance.There are a lot of mistakes in the subtitles. I pointed out many of these by flagging the specific videos where they occurred.Thank you for the opportunity to participate in the beta-test of this course. I hope that my comments are helpful and that I have not missed too much that causes students issues as the course goes live. HTML, CSS and JS materials were covered and were made easy to understand. CodePen and the Write Your Own websites cooperate great with the course. The quizzes are simple while I found he coding practice challenging and yet not too difficult.My only concern is whether the materials covered would help to build a realistic website, say, the homepage of Facebook or Google. It seems though I've finished the course, I still have no idea of how those webpages I see everyday works, let alone code them myself. The following courses in this series focus on Java, so ...By the way, spending 2-3 hours for a week to finish it as soon may help against forgetting. HTML, CSS and JS seem disconnected before you make them cooperate. Cheers!\n",
            "  2% 1236/70000 [00:01<01:12, 943.14it/s]skipping line as its too long (6776):\n",
            "This is a great course and a daring venture for what is really an art form, beyond it's scientific requirements. This part of the specialization needs a little refinement.I posted this in the discussion forum. 7 days ago  EditedFirst of all.....these guys running this data science department have their hands full. They are teaching live classes for students who have spent OODLES (lots) of money to attend this prestigious college . Johns Hopkins is about as good as it gets for a medical degree. Then they are doing experiments and other data science for the research division of Johns Hopkins which is also as good as it gets........THEN they are doing these MOOC courses on top of all their other responsibilities......Dr. Leek is a University of Washington Alumni, which is also top notch for Data Science.The video lesson is flawed, there is no denying it. But I must say these teachers are very open to improvement in the course and your comments on what could be better done are received and acted upon, so I would include them in your thank you letter to the teachers.ALSO I think these MOOC courses are best done by all members of the department contributing. Truly this field IS a team sport. I feel this course was good, but the videos need to be edited and scripted, so unnecessary language, which dilutes the core knowledge, that must be learned, is not diluted where questions are left in the students head about content when being tested. I learned long ago in a college calculus class that if your mark isn't perfect, it's OK, so long as you pass with a high score......even if it is the teachers fault. The course could use better video production with teleprompter scripting......maybe some AV students at Johns Hopkins could get on board. it will happen eventually I'm sure.You want to take a course that is absolutely one of the best courses I've taken anywhere and truly the best online. Try the number one business course on CourseraGROW TO GREATNESS, either part 1 or 2, University of Virginia, Darden School Of Business...........A team created course with one helluva a teacher who is a business person, researcher and award-winning writer. I would recommend this course to ANY student and especially E-Teachers.The problem with this course is that there is a lot of information that can be included but may not be absolutely necessary as a core concept. Needless to say, the more technical skills any employee has, the more insight they will have into their teammate's skills, as well, as the overall mission of the data department and the business it serves. I'm more of a tech and infrastructure person, I'm not real passionate about coding. I find it tedious. The more I learn about it, the more I enjoy it, albeit, from a distance. I can't see myself creating great blocks of scripts, but the more I know about how they are created AND what rules the code in a project must abide by, the better my skills will be as a data center manager. So I'm trying to learn as much as possible about R, Python, and companion programs like ggvis for creating visualizations. I'd say visualizations are an essential skill for a data manager, since you have to present results and projects, questions, and answers to higher ups and other departments.this link comes from the resource section of this coursehttpswww.datacamp.comcoursesggvis-data-visualization-r-tutorialThis link or URL is of much more value to me, than a flawed test question and a reduction in my 100 percent average in the specialization.Without this lesson, in this course, I would not have this valuable resource.Another great link, which has a great FREE print publication as wellhttpwww.processor.com ...these people have been advising data center managers longer than just about anybody !Verbally and in the transcript are some nebulous statements that point toward the main idea, that concept being the more any employee, on any data science or technical team member IS, a jack of all trades, the better. So that could have been included in some more general way on the quiz, because really that is pretty much a general rule, I've found, working in ANY capacity in the tech industry. I have done a great deal of audio editing, working at numerous radio stations, with Adobe Audition. With others like Pro Tools, or any other really good quality AV digital editor the result is streamlined, near seamless, audio-video, or one or the other. You just learn how to read and edit wave forms of all kinds.Years ago, in Dallas, Texas, attending Richland College. I learned a valuable lesson. I was taking a college level Calc-Trig math class being taught by the regular professor's WIFE. I don't know if the professor was sick, but this woman, who was teaching the class for the whole semester, frankly, was not qualified. I had always been considered an illiterate by my high school math teachers, a married couple who, frankly, were highly abnormal even on the geekiest scale. These people were acting like they were a world above most people in the class. Needless to say, I assumed, by their adult opinions, they were sent by God Himself, to educate me thru denigration.I was amazed, how 10 years later, in College math how well I was doing. I was carrying a 100 percent average ! So midterm this faux professor declares, I'll be prefiguring all the arithmetic to be easy, so you won't have to bring your calculators !SO I DIDN'T.......and of course the teacher's wife proclaims.....I didn't have time to make the arithmetic easy so you'd better use your calculators ! I literally had pages and pages of figuring in handwriting accompanying my 3 page test. The result was a C plus on the test. I angrily told the sub teacher I did not bring a calculator to this test because you said it wouldn't be necessary, therefore I must be allowed to redo this test with a calculator ! She of course relented, No that won't be possible...that's not a bad grade.... she continued, what are you worried about ?........I was so peeved, I was going to drop the class. It was too late in the semester, and I was so disgusted with this woman's cavalier dismissal of my perfect grade that I just stopped going to class. The result was a failing final grade.Who ultimately suffered from this dilemma ? That, albeit, unfairly was me.....who created this academic tragedy, by the aggravation of a deeply flawed situation. Once again, that would be me. can't wait to rate this course! I hope I could give 1 start but to show respect I rated it 2. It's just because I personally don't like the instructor and the way he talks, which could ruin the course! I truly hope we could have another instructor in the following courses or the whole specialization would be ruined and so would my interest in database.\n",
            " 17% 11770/70000 [00:14<01:41, 575.90it/s]skipping line as its too long (7015):\n",
            "I will try now a Summary of the whole course, without notes, by memory, so I am going to...Recall the Learning how to learning course of Coursera.Our brain is the most complex thing that human been has discovered in the whole universe. We are still learning how it works and about its functions. At the moment we can talk about two basic modes that our brain uses in the learning process of both academic and non-academic subjects.The first mode is called Focus Mode we put our attention in one specific idea, concept, material, or text that we are trying to learn for a reasonable time not too long. We do not want to make tired our brains. Here we keep away as much as we can any distracting stimulus (phones, internet, friends, etc.). Focus Mode is an important part of the learning process, but not the only one.The second mode is the Diffuse Mode it is related with all the process that our brain does while we are in a more relaxing moment. For instance, when we are sleeping, or doing automatic things like riding a bike, driving a car or just eating or watching television. This process is as important as the focus mode. We hardly could imagine the deep connections that our brain is making during this. The Diffuse mode allows our brains to discover new ways solving problems that sometimes we cannot manage with the focus one.I will continue with more concepts and less words- The importance of mix both modes (focus and diffuse)- The importance of doing physical exercise (work out) in the resting moments or breaks during learning process. Sports or exercise in general maintain our new neural connection alive.- excercesing- The importance of go beyond procrastinationo The use of Pomodoro Techniqueo Having a Plan B to overtake bad habits, and create new better reaction when our minds do not want to do what we need to do because it looks boring or difficult what we are trying to learn.o Understand that the pain we feel when we simply think in these things that we know we need to do but we do not want to, is absolutely normal. This pain or ugly sensation will disappear when we begin to do it.o The more you delay the things you need to do, the more stressed you will become.- The importance of using metaphors and analogies to learn and assimilate new concepts or ideas. The more visual, likely the best.- The importance of recall bring to memory what you are learning. It will be much better than read one time after another the same text, or repeat again and again something that you already know, but maybe you do not really understand in a deep way.- The importance of study in a large period of time, repeating a little bit every day the material you need to memorise, and understand. The more you master the concepts, more time you will leave between every new study session of this main topic, ideas, subject or material.- Create a task listo Do it before going to sleep.o Write on it your goals, and what works for you, and what does not to reach these goals.o Be realistic in your goals. Step by step.o This list will save working memory energy (you will stop thinking any moment oh, what I need to do? Am I forgetting something important?....And all this kind of questions that make you tired and lose your vital energy.- You can improve your learning process if you know how to work in a good way with partners that are achieving the same goals of you. If you study in a group, try too Start on time the study sessions.o Prepare the material before the session.o Try to create answers for the questions if any.o Be active, giving examples or showing possible answers, and asking when you do not know something.o Keep not related with the material small talk as low as you can. And focus the attention of the group in the study object.o If your study group in not helping you, look for another one.- You have to use both sides of your brain. This is important because if you do not, one side of your brain could confuse you making you think that everything you have done in your test is correct. You must go back in your test and check your answers again. It is not a bad idea to review the test in other order than how you just did it.- Taking a testo Check the before-test list before your test.o Ask your teacher everything you cannot understand.o Study hard until the test day, but then try to relax. The stress will never help your brain working well.o Use relaxing techniques like breathing exercises, not only just before and during the test, but also weeks before the exam. Remember practice makes permanent. So, learn how to breathing deeply to liberate the stress.o Order to do your test try to star with the hardest problems or questions, but if you see you are stack on them, Jump to easyo You can change the way you feel about something changing your thoughts and reactions after some sensations. For example you feel yourself completely anxious and stressed, your hands are sweating and your heart bit fast, because the test. Here you can see two options of thoughts about these feelings a) this test will kill me it makes me feel so afraid about it, or b) this test makes me feel excited! I want to do everything I can to pass it!- List before tests- You can change your life changing your thoughts.- Take rest correctly the night before the test this is maybe the most important point of the list before test, because if you do not sleep well your brain will be working with toxic fluids that will not allow you to think in a correct way.- It is absolutely normal have a hard moment during your learning process. Sometimes you may perceive like you are going back on it, but it is not true. That means you are creating new and better basis for your knowledge. If you continue practicing and studying every day at least a little bit, you will improve for sure!- You can learn and improve in any area of learning, not only where you find you have facilities or better capacities. You can also pride and take energy to improve from the very things that other people might use to convince you shouldn’t do this or that, telling you, for instance oh, no, you cannot do this. You are not good in this stuff, try another thing... In the same way, you do not need to feel envy for others.- Sleeping after study will help you to internalize what you are learning. If you dream about the new concepts or ideas is even better.- Try to teach other people what you are learning. This will also help you mastering the concepts.- We can learn how to learn!- We can learn at any time during life!- Learning is beautiful!Thanks a lot my friends! This course is really well put together. The lectures are easy to follow and explain all points very clearly. I appreciate the supplementary quizzes to help me cement the knowledge from the lectures. The course provides tons of extra resources, so that you can entrench yourself in the learning as much as you like--or you can just follow the lectures to learn the essential. My only recommendation would be to add more in-video questions.\n",
            " 58% 40467/70000 [00:49<00:31, 942.77it/s]skipping line as its too long (6448):\n",
            "(I posted this review in a blog httpsguhyasamajacenter.wordpress.com20151003review-of-the-free-coursera-tibetan-buddhist-meditation-and-the-modern-world-lesser-vehicle-course-given-by-uva. Much of the courseware was outstanding. Many of the videos were so poorly done (boring) that I couldn't watch them. (I do not watch people read prepared text in a video. Ever.)----------- From the blog ----------------------------------I recently took the FREE Coursera course, Tibetan Buddhist Meditation and the Modern World. (httpswww.coursera.orglearnbuddhist-meditation) From the course catalog  Tibetan Buddhist Meditation and the Modern World explores the immense variety of meditation practices past and present. We present their histories, their philosophical underpinnings, their transformations in the modern global world, and we give you a chance to reflect upon meditation practices through secular contemplations designed just for this course. (Note In the class overview, it is noted that the term Lesser Vehicle is perjorative but they use it anyway. ??)There are many FREE reasons to take this FREE Lesser Vehicle course (the first of four)1 - An awesome, wonderful hour-long interview with Sharon Salzberg, one of the founders of the Insight Meditation Society. What an awesome lady. I was not aware that she is also a Dzogchen student. (Did I mention it was FREE?) Worth signing up for the course just to skip to Week 6 to watch this interview.2 - Guided Meditations by Dr. Anne Klein and Anam Thubten. Very, very, very nice. FREE, it's ALL FREE.3 - The Science of Mindfulness against the Background of the Scientific Study of Meditation videos with Dr. Clifford Saron, neuroscientist. His videos start in Week 1 and continue through Week 6 in building a basis for understanding the scientific research on meditation. He (and the course) demonstrates what can and cannot (presently) be scientifically proven about meditation. One excellent example Two trained pianists were told to learn a complicated piece of music, one with the piano, and the other only in his imagination. After 2 weeks (I think) of practice, their brains' MRI patterns exhibited almost the exact same changes. Dr. Saron noted that the results are not definitive but still may have implications for the compassionbodhicitta meditations we do.4 An interview on Buddhist Modernism, with David McMahan. Very much academic-oriented. One statement, in particular, struck me since, the more I think about it, the more I think it might be true The Buddhist Tantra teachings are not accepted nor are they popular in the West. For all the Buddhist monastics that visit the USA and the West to grab donations and go back to their home countries, few of them are sticking around to teach complete Tantra classes. The few that do (and do it well) are having a hard time making ends meet. (That's just my opinion, I guess.)There are also short 5-10 minute interviews with Khenpo Tsultrim Lodro (a short snapshot of the Tibetan take on the week's particular subject, which was often better (to me) than the 90min-long talking head version ) and Ven. Tsoknyi Rinpoche (How does Buddhism change in a New Culture and Benefits and Dangers of Secularing Buddhism, the TB rebuttal, as it were. He did note that motivation is the key. Bad agenda  bad results, good motivation will cause good results.)Have I noted the course is FREE? So you can take the course, and the following courses, without doing any of the assignmentsquizzes. Watch (or download) any video or transcript to your heart's content whenever you wish in any order you wish. (That assumes the courses are not taken off-line at a future date.) Further in the course description is a blurb that may point to at least 3 future courses in Mahyna, Vajrayna, and a fourth vehicle, which is explicit in many Tibetan materials, though no standard term ever emerged that was accepted by all sectarian traditions - we will thus term it as the Natural Vehicle or Post Tantra. If the quality of guided meditations (GM) in following classes are even half the quality of this course's GM's, then that's all the reason I need to continue the future classes, too.Course gotchas1. That said (other shoe dropping here), the other half of the course was videos of people reading their prepared academic papers, in monotone or semi-monotone voices. (Transcripts are available. I figure I can read a paper in 5% of the time someone else reads it to me in a video. Ugh.) However, they would probably need the voice of Morgan Freeman, James Earl Jones, B. Cumberbatch or James Spader to keep me awake. To be fair, the content is golden, although the papers seems to be geared to the academic community, rather than the student community. Books and Videos on these subjects are all over Amazon, YouTube, FPMT, Dharma-Documentaries, etc.2. The Sharon Salzberg (SS), in her interview, brought up an excellent point. She noted that she and a noted clinical psychology (CP) scientist (researcher) (whose name I have forgotten) were at a conference where the issue on the table was that someone was having trouble with loving kindness meditation as a first meditation class. SS noted that she would instantly recommend the student change to calm abiding meditation whereas the CP could not change that student's meditation technique to another technique (such as calm abiding) as her research findings would then be invalid. Similarly, many of the non-Buddhist guided meditations that I viewed in this course felt like a physical education or How To class. Do this. Do that. It did not feel as though they lived the material, just taught it. (Whereas it was patently obvious Dr. Klein  Anam Thubten were definitely walking the walk, so to speak, so were able to speak from the heart.)Interviews I did not watch, that may be of great interest to others, include meditation in the school system by Tish Jennings, meditation in the Business Community (an interview with David Mick), the Burmese meditation tradition in an interview with Erik Braun, the MBSR (Meditation Based Stress Reduction) with Susan Bauer-Wu, and meditation in the legal community with Rhonda Magee.And all that is just the first course. Many of it's failings may just be my karmic opinions. The course is worth checking out and watchingreadingmeditating on those parts that interest you. In that respect, the breadth of the course content is quite nice and so well done. Grade B-. \n",
            "100% 70000/70000 [01:26<00:00, 812.58it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt\n",
        "!pip install accelerate -U"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SyhKBuuRJPkp",
        "outputId": "550fb98e-ecb1-4f1e-8459-c68d1b5368d0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (4.40.2)\n",
            "Collecting pytorch-lightning (from -r requirements.txt (line 2))\n",
            "  Downloading pytorch_lightning-2.2.4-py3-none-any.whl (802 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m802.2/802.2 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets>=1.8.0 (from -r requirements.txt (line 3))\n",
            "  Downloading datasets-2.19.1-py3-none-any.whl (542 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (0.1.99)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (3.20.3)\n",
            "Collecting rouge-score (from -r requirements.txt (line 6))\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (3.8.1)\n",
            "Collecting py7zr (from -r requirements.txt (line 8))\n",
            "  Downloading py7zr-0.21.0-py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (2.2.1+cu121)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (0.43.0)\n",
            "Collecting jiwer (from -r requirements.txt (line 11))\n",
            "  Downloading jiwer-3.0.4-py3-none-any.whl (21 kB)\n",
            "Collecting evaluate (from -r requirements.txt (line 12))\n",
            "  Downloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 1)) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 1)) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 1)) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 1)) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 1)) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 1)) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 1)) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 1)) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 1)) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 1)) (4.66.4)\n",
            "Requirement already satisfied: fsspec[http]>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning->-r requirements.txt (line 2)) (2023.6.0)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch-lightning->-r requirements.txt (line 2))\n",
            "  Downloading torchmetrics-1.4.0-py3-none-any.whl (868 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m868.8/868.8 kB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning->-r requirements.txt (line 2)) (4.11.0)\n",
            "Collecting lightning-utilities>=0.8.0 (from pytorch-lightning->-r requirements.txt (line 2))\n",
            "  Downloading lightning_utilities-0.11.2-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=1.8.0->-r requirements.txt (line 3)) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=1.8.0->-r requirements.txt (line 3)) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets>=1.8.0->-r requirements.txt (line 3))\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=1.8.0->-r requirements.txt (line 3)) (2.0.3)\n",
            "Collecting xxhash (from datasets>=1.8.0->-r requirements.txt (line 3))\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets>=1.8.0->-r requirements.txt (line 3))\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=1.8.0->-r requirements.txt (line 3)) (3.9.5)\n",
            "Collecting huggingface-hub<1.0,>=0.19.3 (from transformers->-r requirements.txt (line 1))\n",
            "  Downloading huggingface_hub-0.23.0-py3-none-any.whl (401 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.2/401.2 kB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score->-r requirements.txt (line 6)) (1.4.0)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score->-r requirements.txt (line 6)) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->-r requirements.txt (line 7)) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->-r requirements.txt (line 7)) (1.4.2)\n",
            "Collecting texttable (from py7zr->-r requirements.txt (line 8))\n",
            "  Downloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\n",
            "Collecting pycryptodomex>=3.16.0 (from py7zr->-r requirements.txt (line 8))\n",
            "  Downloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m83.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyzstd>=0.15.9 (from py7zr->-r requirements.txt (line 8))\n",
            "  Downloading pyzstd-0.15.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (411 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.2/411.2 kB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyppmd<1.2.0,>=1.1.0 (from py7zr->-r requirements.txt (line 8))\n",
            "  Downloading pyppmd-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.9/138.9 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pybcj<1.1.0,>=1.0.0 (from py7zr->-r requirements.txt (line 8))\n",
            "  Downloading pybcj-1.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multivolumefile>=0.2.3 (from py7zr->-r requirements.txt (line 8))\n",
            "  Downloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\n",
            "Collecting inflate64<1.1.0,>=1.0.0 (from py7zr->-r requirements.txt (line 8))\n",
            "  Downloading inflate64-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting brotli>=1.1.0 (from py7zr->-r requirements.txt (line 8))\n",
            "  Downloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m83.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from py7zr->-r requirements.txt (line 8)) (5.9.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->-r requirements.txt (line 9)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->-r requirements.txt (line 9)) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->-r requirements.txt (line 9)) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.3->-r requirements.txt (line 9))\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.3->-r requirements.txt (line 9))\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.3->-r requirements.txt (line 9))\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.3->-r requirements.txt (line 9))\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.3->-r requirements.txt (line 9))\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.3->-r requirements.txt (line 9))\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.3->-r requirements.txt (line 9))\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.3->-r requirements.txt (line 9))\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.3->-r requirements.txt (line 9))\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.3->-r requirements.txt (line 9))\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.3->-r requirements.txt (line 9))\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->-r requirements.txt (line 9)) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.3->-r requirements.txt (line 9))\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Collecting rapidfuzz<4,>=3 (from jiwer->-r requirements.txt (line 11))\n",
            "  Downloading rapidfuzz-3.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m96.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=1.8.0->-r requirements.txt (line 3)) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=1.8.0->-r requirements.txt (line 3)) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=1.8.0->-r requirements.txt (line 3)) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=1.8.0->-r requirements.txt (line 3)) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=1.8.0->-r requirements.txt (line 3)) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=1.8.0->-r requirements.txt (line 3)) (4.0.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->pytorch-lightning->-r requirements.txt (line 2)) (67.7.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->-r requirements.txt (line 1)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->-r requirements.txt (line 1)) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->-r requirements.txt (line 1)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->-r requirements.txt (line 1)) (2024.2.2)\n",
            "Collecting pretty-errors==1.2.25 (from torchmetrics>=0.7.0->pytorch-lightning->-r requirements.txt (line 2))\n",
            "  Downloading pretty_errors-1.2.25-py3-none-any.whl (17 kB)\n",
            "Collecting colorama (from pretty-errors==1.2.25->torchmetrics>=0.7.0->pytorch-lightning->-r requirements.txt (line 2))\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3->-r requirements.txt (line 9)) (2.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=1.8.0->-r requirements.txt (line 3)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=1.8.0->-r requirements.txt (line 3)) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=1.8.0->-r requirements.txt (line 3)) (2024.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.3->-r requirements.txt (line 9)) (1.3.0)\n",
            "Building wheels for collected packages: rouge-score\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24933 sha256=9ba78472a096b8bba39c516b385d5ffc00fbc3fd94d89b613430ac94dc1d3807\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "Successfully built rouge-score\n",
            "Installing collected packages: texttable, brotli, xxhash, rapidfuzz, pyzstd, pyppmd, pycryptodomex, pybcj, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, multivolumefile, lightning-utilities, inflate64, dill, colorama, rouge-score, py7zr, pretty-errors, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, jiwer, huggingface-hub, nvidia-cusolver-cu12, datasets, torchmetrics, evaluate, pytorch-lightning\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.20.3\n",
            "    Uninstalling huggingface-hub-0.20.3:\n",
            "      Successfully uninstalled huggingface-hub-0.20.3\n",
            "Successfully installed brotli-1.1.0 colorama-0.4.6 datasets-2.19.1 dill-0.3.8 evaluate-0.4.2 huggingface-hub-0.23.0 inflate64-1.0.0 jiwer-3.0.4 lightning-utilities-0.11.2 multiprocess-0.70.16 multivolumefile-0.2.3 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 pretty-errors-1.2.25 py7zr-0.21.0 pybcj-1.0.2 pycryptodomex-3.20.0 pyppmd-1.1.0 pytorch-lightning-2.2.4 pyzstd-0.15.10 rapidfuzz-3.9.0 rouge-score-0.1.2 texttable-1.7.0 torchmetrics-1.4.0 xxhash-3.4.1\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-0.30.1-py3-none-any.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.6/302.6 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.2.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.23.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.30.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Second Script\n",
        "!python run_summarization.py \\\n",
        "    --model_name_or_path facebook/bart-base \\\n",
        "    --do_train \\\n",
        "    --do_eval \\\n",
        "    --train_file en.train.csv \\\n",
        "    --validation_file en.test.csv \\\n",
        "    --output_dir ./models/bart-base-spelling-en-repro/ \\\n",
        "    --overwrite_output_dir \\\n",
        "    --per_device_train_batch_size=2 \\\n",
        "    --per_device_eval_batch_size=4 \\\n",
        "    --gradient_accumulation_steps=8 \\\n",
        "    --learning_rate=\"3e-4\" \\\n",
        "    --num_train_epochs=\"1\" \\\n",
        "    --predict_with_generate \\\n",
        "    --logging_steps=\"10\" \\\n",
        "    --save_total_limit=\"2\" \\\n",
        "    --max_target_length=1024 \\\n",
        "    --max_source_length=1024\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4w0L82lKEOP",
        "outputId": "39cde563-a260-432c-dafe-b05305a81b43"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-11 18:50:12.611354: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-05-11 18:50:12.611426: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-05-11 18:50:12.660521: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-05-11 18:50:14.083730: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "05/11/2024 18:50:17 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:2547: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=<use_auth_token>' instead.\n",
            "  warnings.warn(\n",
            "Generating train split: 67996 examples [00:01, 51386.93 examples/s]\n",
            "Generating validation split: 2000 examples [00:00, 49508.13 examples/s]\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "model.safetensors: 100% 558M/558M [00:02<00:00, 272MB/s]\n",
            "Running tokenizer on train dataset:   0% 0/67996 [00:00<?, ? examples/s]/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3921: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "Running tokenizer on train dataset: 100% 67996/67996 [01:12<00:00, 936.05 examples/s]\n",
            "Running tokenizer on validation dataset: 100% 2000/2000 [00:01<00:00, 1108.38 examples/s]\n",
            "Downloading builder script: 100% 5.60k/5.60k [00:00<00:00, 19.5MB/s]\n",
            "{'loss': 2.9988, 'grad_norm': 4.500667572021484, 'learning_rate': 0.0002992939515180042, 'epoch': 0.0}\n",
            "{'loss': 1.0643, 'grad_norm': 2.7827706336975098, 'learning_rate': 0.00029858790303600844, 'epoch': 0.0}\n",
            "{'loss': 0.7978, 'grad_norm': 2.746577739715576, 'learning_rate': 0.0002978818545540127, 'epoch': 0.01}\n",
            "{'loss': 0.6546, 'grad_norm': 2.567692279815674, 'learning_rate': 0.0002971758060720169, 'epoch': 0.01}\n",
            "{'loss': 0.5361, 'grad_norm': 2.2394003868103027, 'learning_rate': 0.00029646975759002115, 'epoch': 0.01}\n",
            "{'loss': 0.5137, 'grad_norm': 2.1666100025177, 'learning_rate': 0.0002957637091080254, 'epoch': 0.01}\n",
            "{'loss': 0.446, 'grad_norm': 1.922058343887329, 'learning_rate': 0.0002950576606260296, 'epoch': 0.02}\n",
            "{'loss': 0.4405, 'grad_norm': 1.732611060142517, 'learning_rate': 0.00029435161214403386, 'epoch': 0.02}\n",
            "{'loss': 0.3959, 'grad_norm': 2.2046239376068115, 'learning_rate': 0.0002936455636620381, 'epoch': 0.02}\n",
            "{'loss': 0.4114, 'grad_norm': 2.083113670349121, 'learning_rate': 0.0002929395151800423, 'epoch': 0.02}\n",
            "{'loss': 0.3554, 'grad_norm': 1.671247124671936, 'learning_rate': 0.00029223346669804656, 'epoch': 0.03}\n",
            "{'loss': 0.3577, 'grad_norm': 2.001924514770508, 'learning_rate': 0.0002915274182160508, 'epoch': 0.03}\n",
            "{'loss': 0.3422, 'grad_norm': 2.07259202003479, 'learning_rate': 0.00029082136973405503, 'epoch': 0.03}\n",
            "{'loss': 0.3079, 'grad_norm': 1.7239247560501099, 'learning_rate': 0.00029011532125205927, 'epoch': 0.03}\n",
            "{'loss': 0.3304, 'grad_norm': 1.7430157661437988, 'learning_rate': 0.0002894092727700635, 'epoch': 0.04}\n",
            "{'loss': 0.3009, 'grad_norm': 1.1152617931365967, 'learning_rate': 0.00028870322428806774, 'epoch': 0.04}\n",
            "{'loss': 0.3027, 'grad_norm': 1.5272759199142456, 'learning_rate': 0.00028799717580607197, 'epoch': 0.04}\n",
            "{'loss': 0.2514, 'grad_norm': 1.3934285640716553, 'learning_rate': 0.0002872911273240762, 'epoch': 0.04}\n",
            "{'loss': 0.2556, 'grad_norm': 1.7138372659683228, 'learning_rate': 0.00028658507884208044, 'epoch': 0.04}\n",
            "{'loss': 0.2696, 'grad_norm': 1.7979109287261963, 'learning_rate': 0.00028587903036008473, 'epoch': 0.05}\n",
            "{'loss': 0.2496, 'grad_norm': 1.342785358428955, 'learning_rate': 0.0002851729818780889, 'epoch': 0.05}\n",
            "{'loss': 0.2727, 'grad_norm': 1.5516395568847656, 'learning_rate': 0.0002844669333960932, 'epoch': 0.05}\n",
            "{'loss': 0.2492, 'grad_norm': 6.922358989715576, 'learning_rate': 0.0002837608849140974, 'epoch': 0.05}\n",
            "{'loss': 0.2451, 'grad_norm': 1.5551228523254395, 'learning_rate': 0.00028305483643210167, 'epoch': 0.06}\n",
            "{'loss': 0.253, 'grad_norm': 1.300445318222046, 'learning_rate': 0.00028234878795010585, 'epoch': 0.06}\n",
            "{'loss': 0.2453, 'grad_norm': 1.4355467557907104, 'learning_rate': 0.00028164273946811014, 'epoch': 0.06}\n",
            "{'loss': 0.2072, 'grad_norm': 15.9704008102417, 'learning_rate': 0.0002809366909861143, 'epoch': 0.06}\n",
            "{'loss': 0.4367, 'grad_norm': 1.7124171257019043, 'learning_rate': 0.0002802306425041186, 'epoch': 0.07}\n",
            "{'loss': 0.2716, 'grad_norm': 1.6787582635879517, 'learning_rate': 0.0002795245940221228, 'epoch': 0.07}\n",
            "{'loss': 0.2821, 'grad_norm': 1.2618638277053833, 'learning_rate': 0.0002788185455401271, 'epoch': 0.07}\n",
            "{'loss': 0.2712, 'grad_norm': 2.927347421646118, 'learning_rate': 0.00027811249705813126, 'epoch': 0.07}\n",
            "{'loss': 0.2637, 'grad_norm': 1.9304898977279663, 'learning_rate': 0.00027740644857613555, 'epoch': 0.08}\n",
            "{'loss': 0.2389, 'grad_norm': 1.2599807977676392, 'learning_rate': 0.0002767004000941398, 'epoch': 0.08}\n",
            "{'loss': 0.2143, 'grad_norm': 1.4264953136444092, 'learning_rate': 0.000275994351612144, 'epoch': 0.08}\n",
            "{'loss': 0.2571, 'grad_norm': 1.4229093790054321, 'learning_rate': 0.00027528830313014826, 'epoch': 0.08}\n",
            "{'loss': 0.2292, 'grad_norm': 1.743034839630127, 'learning_rate': 0.0002745822546481525, 'epoch': 0.08}\n",
            "{'loss': 0.2314, 'grad_norm': 1.3582898378372192, 'learning_rate': 0.00027387620616615673, 'epoch': 0.09}\n",
            "{'loss': 0.2694, 'grad_norm': 1.2714539766311646, 'learning_rate': 0.00027317015768416096, 'epoch': 0.09}\n",
            "{'loss': 0.2269, 'grad_norm': 1.0213568210601807, 'learning_rate': 0.0002724641092021652, 'epoch': 0.09}\n",
            "{'loss': 0.2488, 'grad_norm': 0.8783596754074097, 'learning_rate': 0.00027175806072016943, 'epoch': 0.09}\n",
            "{'loss': 0.2175, 'grad_norm': 1.842328667640686, 'learning_rate': 0.00027105201223817367, 'epoch': 0.1}\n",
            "{'loss': 0.2049, 'grad_norm': 1.4185247421264648, 'learning_rate': 0.0002703459637561779, 'epoch': 0.1}\n",
            "{'loss': 0.1819, 'grad_norm': 1.3057924509048462, 'learning_rate': 0.00026963991527418214, 'epoch': 0.1}\n",
            "{'loss': 0.2042, 'grad_norm': 1.563916802406311, 'learning_rate': 0.0002689338667921864, 'epoch': 0.1}\n",
            "{'loss': 0.1977, 'grad_norm': 0.9588648080825806, 'learning_rate': 0.0002682278183101906, 'epoch': 0.11}\n",
            "{'loss': 0.1984, 'grad_norm': 1.3258203268051147, 'learning_rate': 0.00026752176982819485, 'epoch': 0.11}\n",
            "{'loss': 0.2086, 'grad_norm': 1.6783477067947388, 'learning_rate': 0.0002668157213461991, 'epoch': 0.11}\n",
            "{'loss': 0.2128, 'grad_norm': 1.820469617843628, 'learning_rate': 0.0002661096728642033, 'epoch': 0.11}\n",
            "{'loss': 0.2022, 'grad_norm': 1.1493395566940308, 'learning_rate': 0.00026540362438220755, 'epoch': 0.12}\n",
            "{'loss': 0.2199, 'grad_norm': 1.3134245872497559, 'learning_rate': 0.0002646975759002118, 'epoch': 0.12}\n",
            " 12% 500/4249 [11:09<1:22:54,  1.33s/it][WARNING|configuration_utils.py:447] 2024-05-11 19:02:52,380 >> Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n",
            "{'loss': 0.2181, 'grad_norm': 4.0345988273620605, 'learning_rate': 0.000263991527418216, 'epoch': 0.12}\n",
            "{'loss': 0.2233, 'grad_norm': 1.7995352745056152, 'learning_rate': 0.00026328547893622026, 'epoch': 0.12}\n",
            "{'loss': 0.2161, 'grad_norm': 1.6303889751434326, 'learning_rate': 0.0002625794304542245, 'epoch': 0.12}\n",
            "{'loss': 0.1952, 'grad_norm': 1.1785417795181274, 'learning_rate': 0.0002618733819722287, 'epoch': 0.13}\n",
            "{'loss': 0.204, 'grad_norm': 2.5084645748138428, 'learning_rate': 0.00026116733349023296, 'epoch': 0.13}\n",
            "{'loss': 0.1598, 'grad_norm': 0.9784884452819824, 'learning_rate': 0.0002604612850082372, 'epoch': 0.13}\n",
            "{'loss': 0.2045, 'grad_norm': 0.8020937442779541, 'learning_rate': 0.00025975523652624143, 'epoch': 0.13}\n",
            "{'loss': 0.1744, 'grad_norm': 0.9151997566223145, 'learning_rate': 0.00025904918804424567, 'epoch': 0.14}\n",
            "{'loss': 0.1878, 'grad_norm': 1.55955171585083, 'learning_rate': 0.0002583431395622499, 'epoch': 0.14}\n",
            "{'loss': 0.1779, 'grad_norm': 23.52423858642578, 'learning_rate': 0.0002576370910802542, 'epoch': 0.14}\n",
            "{'loss': 0.195, 'grad_norm': 1.1516189575195312, 'learning_rate': 0.0002569310425982584, 'epoch': 0.14}\n",
            "{'loss': 0.205, 'grad_norm': 1.0912541151046753, 'learning_rate': 0.00025622499411626266, 'epoch': 0.15}\n",
            "{'loss': 0.1654, 'grad_norm': 1.2680310010910034, 'learning_rate': 0.00025551894563426684, 'epoch': 0.15}\n",
            "{'loss': 0.1698, 'grad_norm': 1.2099932432174683, 'learning_rate': 0.00025481289715227113, 'epoch': 0.15}\n",
            "{'loss': 0.1883, 'grad_norm': 1.1155511140823364, 'learning_rate': 0.0002541068486702753, 'epoch': 0.15}\n",
            "{'loss': 0.1739, 'grad_norm': 1.2237110137939453, 'learning_rate': 0.0002534008001882796, 'epoch': 0.16}\n",
            "{'loss': 0.2149, 'grad_norm': 2.2334392070770264, 'learning_rate': 0.0002526947517062838, 'epoch': 0.16}\n",
            "{'loss': 0.1755, 'grad_norm': 1.0051536560058594, 'learning_rate': 0.0002519887032242881, 'epoch': 0.16}\n",
            "{'loss': 0.1814, 'grad_norm': 1.5381518602371216, 'learning_rate': 0.00025128265474229225, 'epoch': 0.16}\n",
            "{'loss': 0.1866, 'grad_norm': 1.3390990495681763, 'learning_rate': 0.00025057660626029654, 'epoch': 0.16}\n",
            "{'loss': 0.1928, 'grad_norm': 1.4517531394958496, 'learning_rate': 0.0002498705577783007, 'epoch': 0.17}\n",
            "{'loss': 0.1714, 'grad_norm': 1.4081028699874878, 'learning_rate': 0.000249164509296305, 'epoch': 0.17}\n",
            "{'loss': 0.1856, 'grad_norm': 1.357934832572937, 'learning_rate': 0.00024845846081430925, 'epoch': 0.17}\n",
            "{'loss': 0.1495, 'grad_norm': 1.043090581893921, 'learning_rate': 0.0002477524123323135, 'epoch': 0.17}\n",
            "{'loss': 0.1517, 'grad_norm': 1.2053163051605225, 'learning_rate': 0.0002470463638503177, 'epoch': 0.18}\n",
            "{'loss': 0.1882, 'grad_norm': 2.3474409580230713, 'learning_rate': 0.00024634031536832195, 'epoch': 0.18}\n",
            "{'loss': 0.1796, 'grad_norm': 0.8380926847457886, 'learning_rate': 0.0002456342668863262, 'epoch': 0.18}\n",
            "{'loss': 0.1843, 'grad_norm': 1.3997254371643066, 'learning_rate': 0.0002449282184043304, 'epoch': 0.18}\n",
            "{'loss': 0.1629, 'grad_norm': 1.3143609762191772, 'learning_rate': 0.00024422216992233466, 'epoch': 0.19}\n",
            "{'loss': 0.1583, 'grad_norm': 0.9414114952087402, 'learning_rate': 0.0002435161214403389, 'epoch': 0.19}\n",
            "{'loss': 0.194, 'grad_norm': 1.0523838996887207, 'learning_rate': 0.0002428100729583431, 'epoch': 0.19}\n",
            "{'loss': 0.15, 'grad_norm': 1.0871750116348267, 'learning_rate': 0.00024210402447634737, 'epoch': 0.19}\n",
            "{'loss': 0.1895, 'grad_norm': 1.515932321548462, 'learning_rate': 0.0002413979759943516, 'epoch': 0.2}\n",
            "{'loss': 0.1685, 'grad_norm': 0.7211456298828125, 'learning_rate': 0.00024069192751235584, 'epoch': 0.2}\n",
            "{'loss': 0.1658, 'grad_norm': 0.7664592862129211, 'learning_rate': 0.00023998587903036007, 'epoch': 0.2}\n",
            "{'loss': 0.1468, 'grad_norm': 0.8728657960891724, 'learning_rate': 0.0002392798305483643, 'epoch': 0.2}\n",
            "{'loss': 0.1633, 'grad_norm': 1.3027325868606567, 'learning_rate': 0.00023857378206636854, 'epoch': 0.2}\n",
            "{'loss': 0.1861, 'grad_norm': 1.1061084270477295, 'learning_rate': 0.00023786773358437278, 'epoch': 0.21}\n",
            "{'loss': 0.1589, 'grad_norm': 1.176365613937378, 'learning_rate': 0.000237161685102377, 'epoch': 0.21}\n",
            "{'loss': 0.172, 'grad_norm': 0.8307468295097351, 'learning_rate': 0.00023645563662038127, 'epoch': 0.21}\n",
            "{'loss': 0.1475, 'grad_norm': 1.2759816646575928, 'learning_rate': 0.00023574958813838548, 'epoch': 0.21}\n",
            "{'loss': 0.2048, 'grad_norm': 1.661071538925171, 'learning_rate': 0.00023504353965638974, 'epoch': 0.22}\n",
            "{'loss': 0.1582, 'grad_norm': 1.3144210577011108, 'learning_rate': 0.00023433749117439395, 'epoch': 0.22}\n",
            "{'loss': 0.1567, 'grad_norm': 1.1830146312713623, 'learning_rate': 0.00023363144269239821, 'epoch': 0.22}\n",
            "{'loss': 0.1369, 'grad_norm': 0.7755473256111145, 'learning_rate': 0.00023292539421040242, 'epoch': 0.22}\n",
            "{'loss': 0.1477, 'grad_norm': 0.708152711391449, 'learning_rate': 0.00023221934572840666, 'epoch': 0.23}\n",
            "{'loss': 0.1685, 'grad_norm': 0.9567592144012451, 'learning_rate': 0.0002315132972464109, 'epoch': 0.23}\n",
            "{'loss': 0.1485, 'grad_norm': 1.019717812538147, 'learning_rate': 0.00023080724876441513, 'epoch': 0.23}\n",
            "{'loss': 0.182, 'grad_norm': 3.704050302505493, 'learning_rate': 0.00023010120028241936, 'epoch': 0.23}\n",
            "{'loss': 0.2033, 'grad_norm': 1.3113001585006714, 'learning_rate': 0.0002293951518004236, 'epoch': 0.24}\n",
            " 24% 1000/4249 [22:24<1:12:39,  1.34s/it][WARNING|configuration_utils.py:447] 2024-05-11 19:14:06,840 >> Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n",
            "{'loss': 0.1658, 'grad_norm': 1.586300253868103, 'learning_rate': 0.00022868910331842783, 'epoch': 0.24}\n",
            "{'loss': 0.1675, 'grad_norm': 0.7029755711555481, 'learning_rate': 0.00022798305483643207, 'epoch': 0.24}\n",
            "{'loss': 0.1292, 'grad_norm': 0.9558175802230835, 'learning_rate': 0.00022727700635443633, 'epoch': 0.24}\n",
            "{'loss': 0.1271, 'grad_norm': 0.552598774433136, 'learning_rate': 0.00022657095787244054, 'epoch': 0.24}\n",
            "{'loss': 0.1406, 'grad_norm': 1.160657525062561, 'learning_rate': 0.0002258649093904448, 'epoch': 0.25}\n",
            "{'loss': 0.1456, 'grad_norm': 0.9359754323959351, 'learning_rate': 0.000225158860908449, 'epoch': 0.25}\n",
            "{'loss': 0.1235, 'grad_norm': 0.6799198985099792, 'learning_rate': 0.00022445281242645327, 'epoch': 0.25}\n",
            "{'loss': 0.1721, 'grad_norm': 0.97700434923172, 'learning_rate': 0.00022374676394445748, 'epoch': 0.25}\n",
            "{'loss': 0.2006, 'grad_norm': 0.6762118935585022, 'learning_rate': 0.00022304071546246174, 'epoch': 0.26}\n",
            "{'loss': 0.1647, 'grad_norm': 0.6071228384971619, 'learning_rate': 0.00022233466698046595, 'epoch': 0.26}\n",
            "{'loss': 0.1662, 'grad_norm': 0.7097590565681458, 'learning_rate': 0.0002216286184984702, 'epoch': 0.26}\n",
            "{'loss': 0.1378, 'grad_norm': 0.48786184191703796, 'learning_rate': 0.00022092257001647442, 'epoch': 0.26}\n",
            "{'loss': 0.163, 'grad_norm': 0.7238913178443909, 'learning_rate': 0.00022021652153447868, 'epoch': 0.27}\n",
            "{'loss': 0.1545, 'grad_norm': 1.3571726083755493, 'learning_rate': 0.00021951047305248292, 'epoch': 0.27}\n",
            "{'loss': 0.1375, 'grad_norm': 0.6683372259140015, 'learning_rate': 0.00021880442457048715, 'epoch': 0.27}\n",
            "{'loss': 0.1604, 'grad_norm': 1.9159690141677856, 'learning_rate': 0.0002180983760884914, 'epoch': 0.27}\n",
            "{'loss': 0.1827, 'grad_norm': 1.6136759519577026, 'learning_rate': 0.00021739232760649562, 'epoch': 0.28}\n",
            "{'loss': 0.1283, 'grad_norm': 1.2445416450500488, 'learning_rate': 0.00021668627912449986, 'epoch': 0.28}\n",
            "{'loss': 0.1571, 'grad_norm': 1.143410563468933, 'learning_rate': 0.0002159802306425041, 'epoch': 0.28}\n",
            "{'loss': 0.1511, 'grad_norm': 0.641952633857727, 'learning_rate': 0.00021527418216050833, 'epoch': 0.28}\n",
            "{'loss': 0.1251, 'grad_norm': 0.9618122577667236, 'learning_rate': 0.00021456813367851256, 'epoch': 0.28}\n",
            "{'loss': 0.1481, 'grad_norm': 1.040390133857727, 'learning_rate': 0.0002138620851965168, 'epoch': 0.29}\n",
            "{'loss': 0.1523, 'grad_norm': 2.470360279083252, 'learning_rate': 0.00021315603671452106, 'epoch': 0.29}\n",
            "{'loss': 0.1526, 'grad_norm': 1.15378737449646, 'learning_rate': 0.00021244998823252527, 'epoch': 0.29}\n",
            "{'loss': 0.15, 'grad_norm': 1.2236779928207397, 'learning_rate': 0.00021174393975052953, 'epoch': 0.29}\n",
            "{'loss': 0.1529, 'grad_norm': 0.6974225640296936, 'learning_rate': 0.00021103789126853374, 'epoch': 0.3}\n",
            "{'loss': 0.1534, 'grad_norm': 1.2019627094268799, 'learning_rate': 0.000210331842786538, 'epoch': 0.3}\n",
            "{'loss': 0.1452, 'grad_norm': 1.5245829820632935, 'learning_rate': 0.0002096257943045422, 'epoch': 0.3}\n",
            "{'loss': 0.1617, 'grad_norm': 1.5062931776046753, 'learning_rate': 0.00020891974582254647, 'epoch': 0.3}\n",
            "{'loss': 0.1567, 'grad_norm': 0.5989176034927368, 'learning_rate': 0.00020821369734055068, 'epoch': 0.31}\n",
            "{'loss': 0.1651, 'grad_norm': 1.1063286066055298, 'learning_rate': 0.00020750764885855494, 'epoch': 0.31}\n",
            "{'loss': 0.1485, 'grad_norm': 0.9815717935562134, 'learning_rate': 0.00020680160037655915, 'epoch': 0.31}\n",
            "{'loss': 0.1151, 'grad_norm': 1.218807578086853, 'learning_rate': 0.0002060955518945634, 'epoch': 0.31}\n",
            "{'loss': 0.1406, 'grad_norm': 1.1629014015197754, 'learning_rate': 0.00020538950341256765, 'epoch': 0.32}\n",
            "{'loss': 0.1465, 'grad_norm': 0.6818956732749939, 'learning_rate': 0.00020468345493057188, 'epoch': 0.32}\n",
            "{'loss': 0.1515, 'grad_norm': 0.7869308590888977, 'learning_rate': 0.00020397740644857612, 'epoch': 0.32}\n",
            "{'loss': 0.1781, 'grad_norm': 1.023478627204895, 'learning_rate': 0.00020327135796658035, 'epoch': 0.32}\n",
            "{'loss': 0.1195, 'grad_norm': 1.0383384227752686, 'learning_rate': 0.0002025653094845846, 'epoch': 0.32}\n",
            "{'loss': 0.1334, 'grad_norm': 1.5291595458984375, 'learning_rate': 0.00020185926100258882, 'epoch': 0.33}\n",
            "{'loss': 0.1368, 'grad_norm': 0.9488996267318726, 'learning_rate': 0.00020115321252059306, 'epoch': 0.33}\n",
            "{'loss': 0.131, 'grad_norm': 1.1703331470489502, 'learning_rate': 0.0002004471640385973, 'epoch': 0.33}\n",
            "{'loss': 0.1356, 'grad_norm': 0.6122885346412659, 'learning_rate': 0.00019974111555660153, 'epoch': 0.33}\n",
            "{'loss': 0.1817, 'grad_norm': 0.7869921326637268, 'learning_rate': 0.0001990350670746058, 'epoch': 0.34}\n",
            "{'loss': 0.131, 'grad_norm': 0.691066324710846, 'learning_rate': 0.00019832901859261, 'epoch': 0.34}\n",
            "{'loss': 0.1366, 'grad_norm': 1.4205127954483032, 'learning_rate': 0.00019762297011061426, 'epoch': 0.34}\n",
            "{'loss': 0.1498, 'grad_norm': 0.47127053141593933, 'learning_rate': 0.00019691692162861847, 'epoch': 0.34}\n",
            "{'loss': 0.1512, 'grad_norm': 0.9336820840835571, 'learning_rate': 0.00019621087314662273, 'epoch': 0.35}\n",
            "{'loss': 0.1319, 'grad_norm': 0.8124200105667114, 'learning_rate': 0.00019550482466462694, 'epoch': 0.35}\n",
            "{'loss': 0.1279, 'grad_norm': 0.6921178698539734, 'learning_rate': 0.0001947987761826312, 'epoch': 0.35}\n",
            "{'loss': 0.1251, 'grad_norm': 1.336229681968689, 'learning_rate': 0.0001940927277006354, 'epoch': 0.35}\n",
            " 35% 1500/4249 [33:44<1:00:33,  1.32s/it][WARNING|configuration_utils.py:447] 2024-05-11 19:25:27,348 >> Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n",
            "{'loss': 0.1299, 'grad_norm': 0.9984803795814514, 'learning_rate': 0.00019338667921863967, 'epoch': 0.36}\n",
            "{'loss': 0.1528, 'grad_norm': 1.0903042554855347, 'learning_rate': 0.00019268063073664388, 'epoch': 0.36}\n",
            "{'loss': 0.1446, 'grad_norm': 0.666950523853302, 'learning_rate': 0.00019197458225464814, 'epoch': 0.36}\n",
            "{'loss': 0.1221, 'grad_norm': 0.8104845285415649, 'learning_rate': 0.00019126853377265238, 'epoch': 0.36}\n",
            "{'loss': 0.1164, 'grad_norm': 0.5904582738876343, 'learning_rate': 0.00019056248529065661, 'epoch': 0.36}\n",
            "{'loss': 0.0978, 'grad_norm': 0.7703972458839417, 'learning_rate': 0.00018985643680866085, 'epoch': 0.37}\n",
            "{'loss': 0.1624, 'grad_norm': 1.9245415925979614, 'learning_rate': 0.00018915038832666508, 'epoch': 0.37}\n",
            "{'loss': 0.1289, 'grad_norm': 1.6459194421768188, 'learning_rate': 0.00018844433984466932, 'epoch': 0.37}\n",
            "{'loss': 0.1468, 'grad_norm': 1.6774044036865234, 'learning_rate': 0.00018773829136267355, 'epoch': 0.37}\n",
            "{'loss': 0.1318, 'grad_norm': 1.5878580808639526, 'learning_rate': 0.0001870322428806778, 'epoch': 0.38}\n",
            "{'loss': 0.1242, 'grad_norm': 0.7039738297462463, 'learning_rate': 0.00018632619439868203, 'epoch': 0.38}\n",
            "{'loss': 0.1321, 'grad_norm': 1.1770200729370117, 'learning_rate': 0.00018562014591668626, 'epoch': 0.38}\n",
            "{'loss': 0.1214, 'grad_norm': 2.2201638221740723, 'learning_rate': 0.00018491409743469052, 'epoch': 0.38}\n",
            "{'loss': 0.1219, 'grad_norm': 0.756149411201477, 'learning_rate': 0.00018420804895269473, 'epoch': 0.39}\n",
            "{'loss': 0.1346, 'grad_norm': 0.5444088578224182, 'learning_rate': 0.000183502000470699, 'epoch': 0.39}\n",
            "{'loss': 0.1324, 'grad_norm': 0.7643070816993713, 'learning_rate': 0.0001827959519887032, 'epoch': 0.39}\n",
            "{'loss': 0.1166, 'grad_norm': 0.885362446308136, 'learning_rate': 0.00018208990350670746, 'epoch': 0.39}\n",
            "{'loss': 0.1364, 'grad_norm': 0.7135679721832275, 'learning_rate': 0.00018138385502471167, 'epoch': 0.4}\n",
            "{'loss': 0.1137, 'grad_norm': 0.5533025860786438, 'learning_rate': 0.00018067780654271593, 'epoch': 0.4}\n",
            "{'loss': 0.1131, 'grad_norm': 0.5916281342506409, 'learning_rate': 0.00017997175806072014, 'epoch': 0.4}\n",
            "{'loss': 0.1331, 'grad_norm': 0.8299354314804077, 'learning_rate': 0.0001792657095787244, 'epoch': 0.4}\n",
            "{'loss': 0.1049, 'grad_norm': 0.7944399118423462, 'learning_rate': 0.0001785596610967286, 'epoch': 0.4}\n",
            "{'loss': 0.0997, 'grad_norm': 0.6967952251434326, 'learning_rate': 0.00017785361261473287, 'epoch': 0.41}\n",
            "{'loss': 0.0964, 'grad_norm': 0.42431318759918213, 'learning_rate': 0.0001771475641327371, 'epoch': 0.41}\n",
            "{'loss': 0.1627, 'grad_norm': 0.6767364740371704, 'learning_rate': 0.00017644151565074134, 'epoch': 0.41}\n",
            "{'loss': 0.1173, 'grad_norm': 1.0430301427841187, 'learning_rate': 0.00017573546716874558, 'epoch': 0.41}\n",
            "{'loss': 0.1229, 'grad_norm': 0.6168161034584045, 'learning_rate': 0.00017502941868674981, 'epoch': 0.42}\n",
            "{'loss': 0.1369, 'grad_norm': 1.9067519903182983, 'learning_rate': 0.00017432337020475405, 'epoch': 0.42}\n",
            "{'loss': 0.1243, 'grad_norm': 1.5157831907272339, 'learning_rate': 0.00017361732172275829, 'epoch': 0.42}\n",
            "{'loss': 0.1395, 'grad_norm': 1.5152102708816528, 'learning_rate': 0.00017291127324076252, 'epoch': 0.42}\n",
            "{'loss': 0.1467, 'grad_norm': 0.8262742161750793, 'learning_rate': 0.00017220522475876676, 'epoch': 0.43}\n",
            "{'loss': 0.1405, 'grad_norm': 0.5484256744384766, 'learning_rate': 0.000171499176276771, 'epoch': 0.43}\n",
            "{'loss': 0.1508, 'grad_norm': 0.7796267867088318, 'learning_rate': 0.00017079312779477525, 'epoch': 0.43}\n",
            "{'loss': 0.1332, 'grad_norm': 0.7360082268714905, 'learning_rate': 0.00017008707931277946, 'epoch': 0.43}\n",
            "{'loss': 0.1343, 'grad_norm': 0.8352281451225281, 'learning_rate': 0.00016938103083078372, 'epoch': 0.44}\n",
            "{'loss': 0.0983, 'grad_norm': 0.6898388862609863, 'learning_rate': 0.00016867498234878793, 'epoch': 0.44}\n",
            "{'loss': 0.1091, 'grad_norm': 0.3843238651752472, 'learning_rate': 0.0001679689338667922, 'epoch': 0.44}\n",
            "{'loss': 0.1321, 'grad_norm': 0.7791532278060913, 'learning_rate': 0.0001672628853847964, 'epoch': 0.44}\n",
            "{'loss': 0.1125, 'grad_norm': 0.9906323552131653, 'learning_rate': 0.00016655683690280064, 'epoch': 0.44}\n",
            "{'loss': 0.1328, 'grad_norm': 0.631594181060791, 'learning_rate': 0.00016585078842080487, 'epoch': 0.45}\n",
            "{'loss': 0.1441, 'grad_norm': 1.4922380447387695, 'learning_rate': 0.0001651447399388091, 'epoch': 0.45}\n",
            "{'loss': 0.146, 'grad_norm': 0.6896445751190186, 'learning_rate': 0.00016443869145681334, 'epoch': 0.45}\n",
            "{'loss': 0.1123, 'grad_norm': 0.6470409035682678, 'learning_rate': 0.00016373264297481758, 'epoch': 0.45}\n",
            "{'loss': 0.1204, 'grad_norm': 1.4532804489135742, 'learning_rate': 0.00016302659449282184, 'epoch': 0.46}\n",
            "{'loss': 0.1275, 'grad_norm': 1.5582534074783325, 'learning_rate': 0.00016232054601082605, 'epoch': 0.46}\n",
            "{'loss': 0.1373, 'grad_norm': 0.7568921446800232, 'learning_rate': 0.0001616144975288303, 'epoch': 0.46}\n",
            "{'loss': 0.1281, 'grad_norm': 0.7904714941978455, 'learning_rate': 0.00016090844904683452, 'epoch': 0.46}\n",
            "{'loss': 0.1173, 'grad_norm': 0.48104897141456604, 'learning_rate': 0.00016020240056483878, 'epoch': 0.47}\n",
            "{'loss': 0.1297, 'grad_norm': 0.6676899194717407, 'learning_rate': 0.000159496352082843, 'epoch': 0.47}\n",
            "{'loss': 0.1246, 'grad_norm': 0.7035501599311829, 'learning_rate': 0.00015879030360084725, 'epoch': 0.47}\n",
            " 47% 2000/4249 [44:54<55:04,  1.47s/it][WARNING|configuration_utils.py:447] 2024-05-11 19:36:37,346 >> Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n",
            "{'loss': 0.1501, 'grad_norm': 1.289421796798706, 'learning_rate': 0.00015808425511885146, 'epoch': 0.47}\n",
            "{'loss': 0.1156, 'grad_norm': 0.6186831593513489, 'learning_rate': 0.00015737820663685572, 'epoch': 0.48}\n",
            "{'loss': 0.1317, 'grad_norm': 0.7897233963012695, 'learning_rate': 0.00015667215815485993, 'epoch': 0.48}\n",
            "{'loss': 0.1325, 'grad_norm': 1.1652599573135376, 'learning_rate': 0.0001559661096728642, 'epoch': 0.48}\n",
            "{'loss': 0.1002, 'grad_norm': 0.6400769948959351, 'learning_rate': 0.0001552600611908684, 'epoch': 0.48}\n",
            "{'loss': 0.1232, 'grad_norm': 0.5541133880615234, 'learning_rate': 0.00015455401270887266, 'epoch': 0.48}\n",
            "{'loss': 0.1102, 'grad_norm': 0.605411946773529, 'learning_rate': 0.0001538479642268769, 'epoch': 0.49}\n",
            "{'loss': 0.1228, 'grad_norm': 0.49058374762535095, 'learning_rate': 0.00015314191574488113, 'epoch': 0.49}\n",
            "{'loss': 0.1009, 'grad_norm': 0.7565241456031799, 'learning_rate': 0.00015243586726288537, 'epoch': 0.49}\n",
            "{'loss': 0.129, 'grad_norm': 0.4517477750778198, 'learning_rate': 0.0001517298187808896, 'epoch': 0.49}\n",
            "{'loss': 0.1049, 'grad_norm': 0.7871853709220886, 'learning_rate': 0.00015102377029889384, 'epoch': 0.5}\n",
            "{'loss': 0.117, 'grad_norm': 0.4314168691635132, 'learning_rate': 0.00015031772181689807, 'epoch': 0.5}\n",
            "{'loss': 0.1336, 'grad_norm': 0.8347052335739136, 'learning_rate': 0.0001496116733349023, 'epoch': 0.5}\n",
            "{'loss': 0.1176, 'grad_norm': 0.42039480805397034, 'learning_rate': 0.00014890562485290657, 'epoch': 0.5}\n",
            "{'loss': 0.1362, 'grad_norm': 1.1371684074401855, 'learning_rate': 0.0001481995763709108, 'epoch': 0.51}\n",
            "{'loss': 0.1444, 'grad_norm': 0.8690921664237976, 'learning_rate': 0.00014749352788891504, 'epoch': 0.51}\n",
            "{'loss': 0.1411, 'grad_norm': 0.3952578604221344, 'learning_rate': 0.00014678747940691928, 'epoch': 0.51}\n",
            "{'loss': 0.1127, 'grad_norm': 1.0104624032974243, 'learning_rate': 0.0001460814309249235, 'epoch': 0.51}\n",
            "{'loss': 0.1364, 'grad_norm': 0.7708560824394226, 'learning_rate': 0.00014537538244292775, 'epoch': 0.52}\n",
            "{'loss': 0.1326, 'grad_norm': 3.323113203048706, 'learning_rate': 0.00014466933396093198, 'epoch': 0.52}\n",
            "{'loss': 0.1075, 'grad_norm': 0.5021951198577881, 'learning_rate': 0.00014396328547893622, 'epoch': 0.52}\n",
            "{'loss': 0.1019, 'grad_norm': 0.5558544397354126, 'learning_rate': 0.00014325723699694045, 'epoch': 0.52}\n",
            "{'loss': 0.108, 'grad_norm': 0.7476164102554321, 'learning_rate': 0.0001425511885149447, 'epoch': 0.52}\n",
            "{'loss': 0.1182, 'grad_norm': 0.8783542513847351, 'learning_rate': 0.00014184514003294892, 'epoch': 0.53}\n",
            "{'loss': 0.1048, 'grad_norm': 0.5716719627380371, 'learning_rate': 0.00014113909155095316, 'epoch': 0.53}\n",
            "{'loss': 0.1071, 'grad_norm': 0.41919055581092834, 'learning_rate': 0.0001404330430689574, 'epoch': 0.53}\n",
            "{'loss': 0.1333, 'grad_norm': 0.672885537147522, 'learning_rate': 0.00013972699458696163, 'epoch': 0.53}\n",
            "{'loss': 0.1288, 'grad_norm': 0.7414030432701111, 'learning_rate': 0.00013902094610496586, 'epoch': 0.54}\n",
            "{'loss': 0.1099, 'grad_norm': 1.1601518392562866, 'learning_rate': 0.0001383148976229701, 'epoch': 0.54}\n",
            "{'loss': 0.1049, 'grad_norm': 0.4423375129699707, 'learning_rate': 0.00013760884914097433, 'epoch': 0.54}\n",
            "{'loss': 0.1172, 'grad_norm': 0.9248809218406677, 'learning_rate': 0.00013690280065897857, 'epoch': 0.54}\n",
            "{'loss': 0.1303, 'grad_norm': 1.3502943515777588, 'learning_rate': 0.0001361967521769828, 'epoch': 0.55}\n",
            "{'loss': 0.1182, 'grad_norm': 1.488297939300537, 'learning_rate': 0.00013549070369498704, 'epoch': 0.55}\n",
            "{'loss': 0.1233, 'grad_norm': 0.6636572480201721, 'learning_rate': 0.0001347846552129913, 'epoch': 0.55}\n",
            "{'loss': 0.1102, 'grad_norm': 0.5864549279212952, 'learning_rate': 0.00013407860673099554, 'epoch': 0.55}\n",
            "{'loss': 0.1449, 'grad_norm': 1.9224406480789185, 'learning_rate': 0.00013337255824899977, 'epoch': 0.56}\n",
            "{'loss': 0.1155, 'grad_norm': 1.1239560842514038, 'learning_rate': 0.00013266650976700398, 'epoch': 0.56}\n",
            "{'loss': 0.1193, 'grad_norm': 0.6336050629615784, 'learning_rate': 0.00013196046128500821, 'epoch': 0.56}\n",
            "{'loss': 0.1121, 'grad_norm': 0.9129360914230347, 'learning_rate': 0.00013125441280301245, 'epoch': 0.56}\n",
            "{'loss': 0.1172, 'grad_norm': 0.6220555305480957, 'learning_rate': 0.00013054836432101668, 'epoch': 0.56}\n",
            "{'loss': 0.1184, 'grad_norm': 0.8981531262397766, 'learning_rate': 0.00012984231583902092, 'epoch': 0.57}\n",
            "{'loss': 0.1204, 'grad_norm': 0.7610392570495605, 'learning_rate': 0.00012913626735702515, 'epoch': 0.57}\n",
            "{'loss': 0.1081, 'grad_norm': 0.5133729577064514, 'learning_rate': 0.0001284302188750294, 'epoch': 0.57}\n",
            "{'loss': 0.1142, 'grad_norm': 0.8097817897796631, 'learning_rate': 0.00012772417039303363, 'epoch': 0.57}\n",
            "{'loss': 0.1234, 'grad_norm': 1.8712083101272583, 'learning_rate': 0.00012701812191103786, 'epoch': 0.58}\n",
            "{'loss': 0.1027, 'grad_norm': 0.8425026535987854, 'learning_rate': 0.00012631207342904212, 'epoch': 0.58}\n",
            "{'loss': 0.0916, 'grad_norm': 0.5562009811401367, 'learning_rate': 0.00012560602494704636, 'epoch': 0.58}\n",
            "{'loss': 0.1166, 'grad_norm': 0.45057183504104614, 'learning_rate': 0.0001248999764650506, 'epoch': 0.58}\n",
            "{'loss': 0.1254, 'grad_norm': 0.5411068797111511, 'learning_rate': 0.00012419392798305483, 'epoch': 0.59}\n",
            "{'loss': 0.1411, 'grad_norm': 0.9400952458381653, 'learning_rate': 0.00012348787950105906, 'epoch': 0.59}\n",
            " 59% 2500/4249 [56:10<36:39,  1.26s/it][WARNING|configuration_utils.py:447] 2024-05-11 19:47:53,303 >> Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n",
            "{'loss': 0.1089, 'grad_norm': 0.4275170564651489, 'learning_rate': 0.0001227818310190633, 'epoch': 0.59}\n",
            "{'loss': 0.108, 'grad_norm': 1.2033214569091797, 'learning_rate': 0.00012207578253706753, 'epoch': 0.59}\n",
            "{'loss': 0.1207, 'grad_norm': 1.257379412651062, 'learning_rate': 0.00012136973405507177, 'epoch': 0.6}\n",
            "{'loss': 0.0879, 'grad_norm': 0.7070032954216003, 'learning_rate': 0.000120663685573076, 'epoch': 0.6}\n",
            "{'loss': 0.1087, 'grad_norm': 0.8550868034362793, 'learning_rate': 0.00011995763709108024, 'epoch': 0.6}\n",
            "{'loss': 0.1266, 'grad_norm': 0.8301357626914978, 'learning_rate': 0.00011925158860908447, 'epoch': 0.6}\n",
            "{'loss': 0.1062, 'grad_norm': 0.4070800542831421, 'learning_rate': 0.00011854554012708871, 'epoch': 0.6}\n",
            "{'loss': 0.1147, 'grad_norm': 1.1967391967773438, 'learning_rate': 0.00011783949164509294, 'epoch': 0.61}\n",
            "{'loss': 0.0912, 'grad_norm': 0.5281302332878113, 'learning_rate': 0.00011713344316309718, 'epoch': 0.61}\n",
            "{'loss': 0.1084, 'grad_norm': 0.5271784067153931, 'learning_rate': 0.00011642739468110142, 'epoch': 0.61}\n",
            "{'loss': 0.1242, 'grad_norm': 0.4973151683807373, 'learning_rate': 0.00011572134619910566, 'epoch': 0.61}\n",
            "{'loss': 0.1101, 'grad_norm': 0.4281303882598877, 'learning_rate': 0.0001150152977171099, 'epoch': 0.62}\n",
            "{'loss': 0.1182, 'grad_norm': 0.5142689347267151, 'learning_rate': 0.00011430924923511413, 'epoch': 0.62}\n",
            "{'loss': 0.0943, 'grad_norm': 0.5125661492347717, 'learning_rate': 0.00011360320075311837, 'epoch': 0.62}\n",
            "{'loss': 0.0948, 'grad_norm': 0.43077680468559265, 'learning_rate': 0.0001128971522711226, 'epoch': 0.62}\n",
            "{'loss': 0.0853, 'grad_norm': 0.5074141621589661, 'learning_rate': 0.00011219110378912684, 'epoch': 0.63}\n",
            "{'loss': 0.1104, 'grad_norm': 0.8260855674743652, 'learning_rate': 0.00011148505530713107, 'epoch': 0.63}\n",
            "{'loss': 0.1256, 'grad_norm': 0.7819215059280396, 'learning_rate': 0.00011077900682513531, 'epoch': 0.63}\n",
            "{'loss': 0.1027, 'grad_norm': 0.46884438395500183, 'learning_rate': 0.00011007295834313955, 'epoch': 0.63}\n",
            "{'loss': 0.112, 'grad_norm': 0.9515593647956848, 'learning_rate': 0.00010936690986114378, 'epoch': 0.64}\n",
            "{'loss': 0.1053, 'grad_norm': 0.3602767586708069, 'learning_rate': 0.00010866086137914803, 'epoch': 0.64}\n",
            "{'loss': 0.112, 'grad_norm': 0.7740781903266907, 'learning_rate': 0.00010795481289715226, 'epoch': 0.64}\n",
            "{'loss': 0.0985, 'grad_norm': 0.5003033876419067, 'learning_rate': 0.0001072487644151565, 'epoch': 0.64}\n",
            "{'loss': 0.1113, 'grad_norm': 0.4092664122581482, 'learning_rate': 0.00010654271593316073, 'epoch': 0.64}\n",
            "{'loss': 0.0909, 'grad_norm': 0.446584552526474, 'learning_rate': 0.00010583666745116497, 'epoch': 0.65}\n",
            "{'loss': 0.0954, 'grad_norm': 0.3130131661891937, 'learning_rate': 0.0001051306189691692, 'epoch': 0.65}\n",
            "{'loss': 0.1132, 'grad_norm': 0.7232083082199097, 'learning_rate': 0.00010442457048717344, 'epoch': 0.65}\n",
            "{'loss': 0.1045, 'grad_norm': 0.5579691529273987, 'learning_rate': 0.00010371852200517768, 'epoch': 0.65}\n",
            "{'loss': 0.1215, 'grad_norm': 0.5319089889526367, 'learning_rate': 0.00010301247352318191, 'epoch': 0.66}\n",
            "{'loss': 0.111, 'grad_norm': 0.516445517539978, 'learning_rate': 0.00010230642504118615, 'epoch': 0.66}\n",
            "{'loss': 0.1126, 'grad_norm': 0.25264236330986023, 'learning_rate': 0.0001016003765591904, 'epoch': 0.66}\n",
            "{'loss': 0.1306, 'grad_norm': 0.7910987138748169, 'learning_rate': 0.00010089432807719463, 'epoch': 0.66}\n",
            "{'loss': 0.0967, 'grad_norm': 0.7823461890220642, 'learning_rate': 0.00010018827959519886, 'epoch': 0.67}\n",
            "{'loss': 0.1296, 'grad_norm': 0.7126127481460571, 'learning_rate': 9.94822311132031e-05, 'epoch': 0.67}\n",
            "{'loss': 0.1115, 'grad_norm': 0.9327739477157593, 'learning_rate': 9.877618263120733e-05, 'epoch': 0.67}\n",
            "{'loss': 0.1055, 'grad_norm': 0.7680268883705139, 'learning_rate': 9.807013414921157e-05, 'epoch': 0.67}\n",
            "{'loss': 0.0951, 'grad_norm': 0.7711540460586548, 'learning_rate': 9.73640856672158e-05, 'epoch': 0.68}\n",
            "{'loss': 0.1087, 'grad_norm': 0.5041959881782532, 'learning_rate': 9.665803718522004e-05, 'epoch': 0.68}\n",
            "{'loss': 0.1176, 'grad_norm': 0.5102591514587402, 'learning_rate': 9.595198870322428e-05, 'epoch': 0.68}\n",
            "{'loss': 0.1091, 'grad_norm': 0.7100384831428528, 'learning_rate': 9.524594022122851e-05, 'epoch': 0.68}\n",
            "{'loss': 0.1251, 'grad_norm': 0.6806867122650146, 'learning_rate': 9.453989173923276e-05, 'epoch': 0.68}\n",
            "{'loss': 0.0835, 'grad_norm': 0.6659530401229858, 'learning_rate': 9.3833843257237e-05, 'epoch': 0.69}\n",
            "{'loss': 0.0893, 'grad_norm': 0.4317012429237366, 'learning_rate': 9.312779477524123e-05, 'epoch': 0.69}\n",
            "{'loss': 0.0905, 'grad_norm': 0.5916824340820312, 'learning_rate': 9.242174629324546e-05, 'epoch': 0.69}\n",
            "{'loss': 0.1063, 'grad_norm': 0.7429795265197754, 'learning_rate': 9.17156978112497e-05, 'epoch': 0.69}\n",
            "{'loss': 0.1042, 'grad_norm': 0.87420254945755, 'learning_rate': 9.100964932925394e-05, 'epoch': 0.7}\n",
            "{'loss': 0.1045, 'grad_norm': 0.49567267298698425, 'learning_rate': 9.030360084725817e-05, 'epoch': 0.7}\n",
            "{'loss': 0.0884, 'grad_norm': 2.633138418197632, 'learning_rate': 8.95975523652624e-05, 'epoch': 0.7}\n",
            "{'loss': 0.0848, 'grad_norm': 0.33752286434173584, 'learning_rate': 8.889150388326664e-05, 'epoch': 0.7}\n",
            "{'loss': 0.0971, 'grad_norm': 0.5974826812744141, 'learning_rate': 8.818545540127088e-05, 'epoch': 0.71}\n",
            " 71% 3000/4249 [1:07:24<27:35,  1.33s/it][WARNING|configuration_utils.py:447] 2024-05-11 19:59:06,582 >> Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n",
            "{'loss': 0.1165, 'grad_norm': 0.43427976965904236, 'learning_rate': 8.747940691927512e-05, 'epoch': 0.71}\n",
            "{'loss': 0.1084, 'grad_norm': 0.7770646810531616, 'learning_rate': 8.677335843727936e-05, 'epoch': 0.71}\n",
            "{'loss': 0.111, 'grad_norm': 0.5276495218276978, 'learning_rate': 8.60673099552836e-05, 'epoch': 0.71}\n",
            "{'loss': 0.0972, 'grad_norm': 0.9737383127212524, 'learning_rate': 8.536126147328783e-05, 'epoch': 0.72}\n",
            "{'loss': 0.093, 'grad_norm': 0.36562997102737427, 'learning_rate': 8.465521299129207e-05, 'epoch': 0.72}\n",
            "{'loss': 0.1263, 'grad_norm': 0.8244528770446777, 'learning_rate': 8.39491645092963e-05, 'epoch': 0.72}\n",
            "{'loss': 0.1251, 'grad_norm': 1.9532008171081543, 'learning_rate': 8.324311602730054e-05, 'epoch': 0.72}\n",
            "{'loss': 0.0875, 'grad_norm': 0.572896420955658, 'learning_rate': 8.253706754530477e-05, 'epoch': 0.72}\n",
            "{'loss': 0.1023, 'grad_norm': 1.2975929975509644, 'learning_rate': 8.1831019063309e-05, 'epoch': 0.73}\n",
            "{'loss': 0.1019, 'grad_norm': 0.5758102536201477, 'learning_rate': 8.112497058131324e-05, 'epoch': 0.73}\n",
            "{'loss': 0.1128, 'grad_norm': 0.553327202796936, 'learning_rate': 8.041892209931749e-05, 'epoch': 0.73}\n",
            "{'loss': 0.1237, 'grad_norm': 0.5465438961982727, 'learning_rate': 7.971287361732173e-05, 'epoch': 0.73}\n",
            "{'loss': 0.0964, 'grad_norm': 0.46917715668678284, 'learning_rate': 7.900682513532596e-05, 'epoch': 0.74}\n",
            "{'loss': 0.0901, 'grad_norm': 0.8454899787902832, 'learning_rate': 7.83007766533302e-05, 'epoch': 0.74}\n",
            "{'loss': 0.1119, 'grad_norm': 0.8698781728744507, 'learning_rate': 7.759472817133443e-05, 'epoch': 0.74}\n",
            "{'loss': 0.1122, 'grad_norm': 1.7399003505706787, 'learning_rate': 7.688867968933867e-05, 'epoch': 0.74}\n",
            "{'loss': 0.09, 'grad_norm': 0.4506986141204834, 'learning_rate': 7.61826312073429e-05, 'epoch': 0.75}\n",
            "{'loss': 0.1194, 'grad_norm': 0.7856936454772949, 'learning_rate': 7.547658272534714e-05, 'epoch': 0.75}\n",
            "{'loss': 0.1167, 'grad_norm': 0.5778619050979614, 'learning_rate': 7.477053424335137e-05, 'epoch': 0.75}\n",
            "{'loss': 0.0813, 'grad_norm': 0.4940952658653259, 'learning_rate': 7.40644857613556e-05, 'epoch': 0.75}\n",
            "{'loss': 0.0966, 'grad_norm': 1.1496696472167969, 'learning_rate': 7.335843727935984e-05, 'epoch': 0.76}\n",
            "{'loss': 0.0956, 'grad_norm': 0.4551859498023987, 'learning_rate': 7.265238879736408e-05, 'epoch': 0.76}\n",
            "{'loss': 0.1225, 'grad_norm': 0.5476594567298889, 'learning_rate': 7.194634031536831e-05, 'epoch': 0.76}\n",
            "{'loss': 0.0996, 'grad_norm': 0.4413054287433624, 'learning_rate': 7.124029183337255e-05, 'epoch': 0.76}\n",
            "{'loss': 0.0946, 'grad_norm': 0.6522489190101624, 'learning_rate': 7.053424335137678e-05, 'epoch': 0.76}\n",
            "{'loss': 0.0788, 'grad_norm': 0.4750779867172241, 'learning_rate': 6.982819486938102e-05, 'epoch': 0.77}\n",
            "{'loss': 0.0841, 'grad_norm': 0.336505264043808, 'learning_rate': 6.912214638738527e-05, 'epoch': 0.77}\n",
            "{'loss': 0.0991, 'grad_norm': 1.4274874925613403, 'learning_rate': 6.84160979053895e-05, 'epoch': 0.77}\n",
            "{'loss': 0.1172, 'grad_norm': 0.6464115977287292, 'learning_rate': 6.771004942339374e-05, 'epoch': 0.77}\n",
            "{'loss': 0.09, 'grad_norm': 0.35535725951194763, 'learning_rate': 6.700400094139797e-05, 'epoch': 0.78}\n",
            "{'loss': 0.089, 'grad_norm': 0.22626227140426636, 'learning_rate': 6.62979524594022e-05, 'epoch': 0.78}\n",
            "{'loss': 0.0851, 'grad_norm': 0.6091925501823425, 'learning_rate': 6.559190397740644e-05, 'epoch': 0.78}\n",
            "{'loss': 0.1001, 'grad_norm': 2.3381729125976562, 'learning_rate': 6.488585549541068e-05, 'epoch': 0.78}\n",
            "{'loss': 0.0985, 'grad_norm': 0.41597291827201843, 'learning_rate': 6.417980701341491e-05, 'epoch': 0.79}\n",
            "{'loss': 0.0877, 'grad_norm': 0.6187950372695923, 'learning_rate': 6.347375853141915e-05, 'epoch': 0.79}\n",
            "{'loss': 0.1074, 'grad_norm': 0.4807620942592621, 'learning_rate': 6.276771004942338e-05, 'epoch': 0.79}\n",
            "{'loss': 0.1044, 'grad_norm': 0.2998965382575989, 'learning_rate': 6.206166156742763e-05, 'epoch': 0.79}\n",
            "{'loss': 0.1073, 'grad_norm': 0.5904129147529602, 'learning_rate': 6.135561308543187e-05, 'epoch': 0.8}\n",
            "{'loss': 0.1121, 'grad_norm': 0.6356788277626038, 'learning_rate': 6.06495646034361e-05, 'epoch': 0.8}\n",
            "{'loss': 0.1103, 'grad_norm': 0.9147433638572693, 'learning_rate': 5.994351612144034e-05, 'epoch': 0.8}\n",
            "{'loss': 0.0965, 'grad_norm': 0.8032605051994324, 'learning_rate': 5.923746763944457e-05, 'epoch': 0.8}\n",
            "{'loss': 0.1007, 'grad_norm': 0.7935906052589417, 'learning_rate': 5.853141915744881e-05, 'epoch': 0.8}\n",
            "{'loss': 0.0882, 'grad_norm': 0.4112412631511688, 'learning_rate': 5.782537067545304e-05, 'epoch': 0.81}\n",
            "{'loss': 0.1019, 'grad_norm': 0.8190514445304871, 'learning_rate': 5.7119322193457284e-05, 'epoch': 0.81}\n",
            "{'loss': 0.1053, 'grad_norm': 0.6029698848724365, 'learning_rate': 5.641327371146152e-05, 'epoch': 0.81}\n",
            "{'loss': 0.1044, 'grad_norm': 0.43347781896591187, 'learning_rate': 5.5707225229465755e-05, 'epoch': 0.81}\n",
            "{'loss': 0.0982, 'grad_norm': 1.5235440731048584, 'learning_rate': 5.500117674746999e-05, 'epoch': 0.82}\n",
            "{'loss': 0.1078, 'grad_norm': 0.5716174244880676, 'learning_rate': 5.4295128265474225e-05, 'epoch': 0.82}\n",
            "{'loss': 0.0915, 'grad_norm': 1.5008090734481812, 'learning_rate': 5.358907978347847e-05, 'epoch': 0.82}\n",
            "{'loss': 0.0892, 'grad_norm': 0.49782001972198486, 'learning_rate': 5.28830313014827e-05, 'epoch': 0.82}\n",
            " 82% 3500/4249 [1:18:38<15:59,  1.28s/it][WARNING|configuration_utils.py:447] 2024-05-11 20:10:21,083 >> Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n",
            "{'loss': 0.0905, 'grad_norm': 0.4466950297355652, 'learning_rate': 5.217698281948694e-05, 'epoch': 0.83}\n",
            "{'loss': 0.1128, 'grad_norm': 0.5504721403121948, 'learning_rate': 5.147093433749117e-05, 'epoch': 0.83}\n",
            "{'loss': 0.0876, 'grad_norm': 0.4870951473712921, 'learning_rate': 5.076488585549541e-05, 'epoch': 0.83}\n",
            "{'loss': 0.1004, 'grad_norm': 0.6789172887802124, 'learning_rate': 5.005883737349965e-05, 'epoch': 0.83}\n",
            "{'loss': 0.0862, 'grad_norm': 0.5021870136260986, 'learning_rate': 4.935278889150388e-05, 'epoch': 0.84}\n",
            "{'loss': 0.0994, 'grad_norm': 0.5829181671142578, 'learning_rate': 4.864674040950811e-05, 'epoch': 0.84}\n",
            "{'loss': 0.1144, 'grad_norm': 1.029181957244873, 'learning_rate': 4.794069192751235e-05, 'epoch': 0.84}\n",
            "{'loss': 0.106, 'grad_norm': 0.6730376482009888, 'learning_rate': 4.723464344551658e-05, 'epoch': 0.84}\n",
            "{'loss': 0.0896, 'grad_norm': 0.6129499673843384, 'learning_rate': 4.652859496352082e-05, 'epoch': 0.84}\n",
            "{'loss': 0.0846, 'grad_norm': 0.422830194234848, 'learning_rate': 4.582254648152506e-05, 'epoch': 0.85}\n",
            "{'loss': 0.1059, 'grad_norm': 0.5306664109230042, 'learning_rate': 4.5116497999529296e-05, 'epoch': 0.85}\n",
            "{'loss': 0.1132, 'grad_norm': 0.6436883807182312, 'learning_rate': 4.441044951753353e-05, 'epoch': 0.85}\n",
            "{'loss': 0.0864, 'grad_norm': 0.4121890962123871, 'learning_rate': 4.3704401035537766e-05, 'epoch': 0.85}\n",
            "{'loss': 0.1011, 'grad_norm': 0.42521169781684875, 'learning_rate': 4.2998352553542e-05, 'epoch': 0.86}\n",
            "{'loss': 0.1093, 'grad_norm': 0.49623095989227295, 'learning_rate': 4.229230407154624e-05, 'epoch': 0.86}\n",
            "{'loss': 0.1009, 'grad_norm': 0.5516742467880249, 'learning_rate': 4.158625558955048e-05, 'epoch': 0.86}\n",
            "{'loss': 0.0717, 'grad_norm': 0.37128451466560364, 'learning_rate': 4.0880207107554713e-05, 'epoch': 0.86}\n",
            "{'loss': 0.0891, 'grad_norm': 0.3802624046802521, 'learning_rate': 4.017415862555895e-05, 'epoch': 0.87}\n",
            "{'loss': 0.0863, 'grad_norm': 0.35558944940567017, 'learning_rate': 3.9468110143563184e-05, 'epoch': 0.87}\n",
            "{'loss': 0.0946, 'grad_norm': 0.2548139989376068, 'learning_rate': 3.8762061661567426e-05, 'epoch': 0.87}\n",
            "{'loss': 0.0794, 'grad_norm': 0.3489900827407837, 'learning_rate': 3.805601317957166e-05, 'epoch': 0.87}\n",
            "{'loss': 0.1026, 'grad_norm': 0.7514833807945251, 'learning_rate': 3.7349964697575896e-05, 'epoch': 0.88}\n",
            "{'loss': 0.107, 'grad_norm': 0.28846803307533264, 'learning_rate': 3.664391621558013e-05, 'epoch': 0.88}\n",
            "{'loss': 0.0839, 'grad_norm': 0.3054257333278656, 'learning_rate': 3.5937867733584366e-05, 'epoch': 0.88}\n",
            "{'loss': 0.099, 'grad_norm': 0.487393856048584, 'learning_rate': 3.523181925158861e-05, 'epoch': 0.88}\n",
            "{'loss': 0.0873, 'grad_norm': 0.7874276041984558, 'learning_rate': 3.4525770769592843e-05, 'epoch': 0.88}\n",
            "{'loss': 0.0854, 'grad_norm': 0.3583498001098633, 'learning_rate': 3.381972228759708e-05, 'epoch': 0.89}\n",
            "{'loss': 0.1106, 'grad_norm': 0.5606823563575745, 'learning_rate': 3.3113673805601314e-05, 'epoch': 0.89}\n",
            "{'loss': 0.1138, 'grad_norm': 0.48208296298980713, 'learning_rate': 3.240762532360555e-05, 'epoch': 0.89}\n",
            "{'loss': 0.0877, 'grad_norm': 1.026995301246643, 'learning_rate': 3.170157684160979e-05, 'epoch': 0.89}\n",
            "{'loss': 0.069, 'grad_norm': 0.7940952777862549, 'learning_rate': 3.0995528359614026e-05, 'epoch': 0.9}\n",
            "{'loss': 0.0884, 'grad_norm': 0.7711090445518494, 'learning_rate': 3.028947987761826e-05, 'epoch': 0.9}\n",
            "{'loss': 0.0929, 'grad_norm': 0.6985650062561035, 'learning_rate': 2.9583431395622496e-05, 'epoch': 0.9}\n",
            "{'loss': 0.1166, 'grad_norm': 0.5291894674301147, 'learning_rate': 2.8877382913626735e-05, 'epoch': 0.9}\n",
            "{'loss': 0.0904, 'grad_norm': 0.3929837644100189, 'learning_rate': 2.817133443163097e-05, 'epoch': 0.91}\n",
            "{'loss': 0.0986, 'grad_norm': 0.492017537355423, 'learning_rate': 2.746528594963521e-05, 'epoch': 0.91}\n",
            "{'loss': 0.0897, 'grad_norm': 0.5756918787956238, 'learning_rate': 2.6759237467639444e-05, 'epoch': 0.91}\n",
            "{'loss': 0.0799, 'grad_norm': 0.5781024098396301, 'learning_rate': 2.605318898564368e-05, 'epoch': 0.91}\n",
            "{'loss': 0.0889, 'grad_norm': 0.28270334005355835, 'learning_rate': 2.5347140503647918e-05, 'epoch': 0.92}\n",
            "{'loss': 0.0788, 'grad_norm': 0.5788043737411499, 'learning_rate': 2.464109202165215e-05, 'epoch': 0.92}\n",
            "{'loss': 0.0914, 'grad_norm': 0.563836932182312, 'learning_rate': 2.3935043539656384e-05, 'epoch': 0.92}\n",
            "{'loss': 0.1057, 'grad_norm': 0.4077290892601013, 'learning_rate': 2.3228995057660623e-05, 'epoch': 0.92}\n",
            "{'loss': 0.0812, 'grad_norm': 0.6209468841552734, 'learning_rate': 2.2522946575664858e-05, 'epoch': 0.92}\n",
            "{'loss': 0.0951, 'grad_norm': 0.542506754398346, 'learning_rate': 2.1816898093669097e-05, 'epoch': 0.93}\n",
            "{'loss': 0.1023, 'grad_norm': 0.5754973292350769, 'learning_rate': 2.1110849611673332e-05, 'epoch': 0.93}\n",
            "{'loss': 0.0997, 'grad_norm': 0.3798030912876129, 'learning_rate': 2.0404801129677567e-05, 'epoch': 0.93}\n",
            "{'loss': 0.1056, 'grad_norm': 0.6593634486198425, 'learning_rate': 1.9698752647681806e-05, 'epoch': 0.93}\n",
            "{'loss': 0.0795, 'grad_norm': 0.46481505036354065, 'learning_rate': 1.899270416568604e-05, 'epoch': 0.94}\n",
            "{'loss': 0.0809, 'grad_norm': 0.5140686631202698, 'learning_rate': 1.828665568369028e-05, 'epoch': 0.94}\n",
            "{'loss': 0.0851, 'grad_norm': 0.8201892375946045, 'learning_rate': 1.7580607201694515e-05, 'epoch': 0.94}\n",
            " 94% 4000/4249 [1:29:54<05:02,  1.22s/it][WARNING|configuration_utils.py:447] 2024-05-11 20:21:36,753 >> Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n",
            "{'loss': 0.0789, 'grad_norm': 0.3848946690559387, 'learning_rate': 1.687455871969875e-05, 'epoch': 0.94}\n",
            "{'loss': 0.0841, 'grad_norm': 0.3362932503223419, 'learning_rate': 1.6168510237702988e-05, 'epoch': 0.95}\n",
            "{'loss': 0.1004, 'grad_norm': 0.400037556886673, 'learning_rate': 1.5462461755707223e-05, 'epoch': 0.95}\n",
            "{'loss': 0.0977, 'grad_norm': 0.6505069136619568, 'learning_rate': 1.475641327371146e-05, 'epoch': 0.95}\n",
            "{'loss': 0.085, 'grad_norm': 0.710784375667572, 'learning_rate': 1.4050364791715697e-05, 'epoch': 0.95}\n",
            "{'loss': 0.1044, 'grad_norm': 0.4263714849948883, 'learning_rate': 1.3344316309719934e-05, 'epoch': 0.96}\n",
            "{'loss': 0.1113, 'grad_norm': 0.42400240898132324, 'learning_rate': 1.2638267827724171e-05, 'epoch': 0.96}\n",
            "{'loss': 0.0792, 'grad_norm': 0.2722209393978119, 'learning_rate': 1.1932219345728404e-05, 'epoch': 0.96}\n",
            "{'loss': 0.1044, 'grad_norm': 0.9779515862464905, 'learning_rate': 1.1226170863732641e-05, 'epoch': 0.96}\n",
            "{'loss': 0.1043, 'grad_norm': 1.028387188911438, 'learning_rate': 1.0520122381736878e-05, 'epoch': 0.96}\n",
            "{'loss': 0.087, 'grad_norm': 0.5009176135063171, 'learning_rate': 9.814073899741115e-06, 'epoch': 0.97}\n",
            "{'loss': 0.092, 'grad_norm': 0.33020302653312683, 'learning_rate': 9.10802541774535e-06, 'epoch': 0.97}\n",
            "{'loss': 0.075, 'grad_norm': 0.4314991533756256, 'learning_rate': 8.401976935749587e-06, 'epoch': 0.97}\n",
            "{'loss': 0.0892, 'grad_norm': 0.6121822595596313, 'learning_rate': 7.695928453753824e-06, 'epoch': 0.97}\n",
            "{'loss': 0.0755, 'grad_norm': 0.3374115824699402, 'learning_rate': 6.989879971758061e-06, 'epoch': 0.98}\n",
            "{'loss': 0.0957, 'grad_norm': 0.5865825414657593, 'learning_rate': 6.283831489762297e-06, 'epoch': 0.98}\n",
            "{'loss': 0.0849, 'grad_norm': 0.2131696194410324, 'learning_rate': 5.577783007766533e-06, 'epoch': 0.98}\n",
            "{'loss': 0.098, 'grad_norm': 1.3489303588867188, 'learning_rate': 4.871734525770769e-06, 'epoch': 0.98}\n",
            "{'loss': 0.0847, 'grad_norm': 0.15470068156719208, 'learning_rate': 4.1656860437750056e-06, 'epoch': 0.99}\n",
            "{'loss': 0.1094, 'grad_norm': 0.8059414625167847, 'learning_rate': 3.459637561779242e-06, 'epoch': 0.99}\n",
            "{'loss': 0.0867, 'grad_norm': 0.6808902621269226, 'learning_rate': 2.753589079783478e-06, 'epoch': 0.99}\n",
            "{'loss': 0.0866, 'grad_norm': 0.29802441596984863, 'learning_rate': 2.0475405977877145e-06, 'epoch': 0.99}\n",
            "{'loss': 0.0758, 'grad_norm': 0.5227815508842468, 'learning_rate': 1.341492115791951e-06, 'epoch': 1.0}\n",
            "{'loss': 0.0906, 'grad_norm': 0.25185248255729675, 'learning_rate': 6.354436337961872e-07, 'epoch': 1.0}\n",
            "{'train_runtime': 5739.131, 'train_samples_per_second': 11.848, 'train_steps_per_second': 0.74, 'train_loss': 0.1519955188758403, 'epoch': 1.0}\n",
            "100% 4249/4249 [1:35:39<00:00,  1.35s/it]\n",
            "[WARNING|configuration_utils.py:447] 2024-05-11 20:27:21,678 >> Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n",
            "***** train metrics *****\n",
            "  epoch                    =     0.9998\n",
            "  total_flos               =  9664010GF\n",
            "  train_loss               =      0.152\n",
            "  train_runtime            = 1:35:39.13\n",
            "  train_samples            =      67996\n",
            "  train_samples_per_second =     11.848\n",
            "  train_steps_per_second   =       0.74\n",
            "100% 500/500 [41:54<00:00,  3.96s/it]Traceback (most recent call last):\n",
            "  File \"/content/run_summarization.py\", line 708, in <module>\n",
            "    main()\n",
            "  File \"/content/run_summarization.py\", line 650, in main\n",
            "    metrics = trainer.evaluate(max_length=max_length, num_beams=num_beams, metric_key_prefix=\"eval\")\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/trainer_seq2seq.py\", line 180, in evaluate\n",
            "    return super().evaluate(eval_dataset, ignore_keys=ignore_keys, metric_key_prefix=metric_key_prefix)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\", line 3467, in evaluate\n",
            "    output = eval_loop(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\", line 3719, in evaluation_loop\n",
            "    metrics = self.compute_metrics(EvalPrediction(predictions=all_preds, label_ids=all_labels))\n",
            "  File \"/content/run_summarization.py\", line 590, in compute_metrics\n",
            "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\", line 3771, in batch_decode\n",
            "    return [\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\", line 3772, in <listcomp>\n",
            "    self.decode(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\", line 3811, in decode\n",
            "    return self._decode(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_fast.py\", line 625, in _decode\n",
            "    text = self._tokenizer.decode(token_ids, skip_special_tokens=skip_special_tokens)\n",
            "OverflowError: out of range integral type conversion attempted\n",
            "100% 500/500 [41:54<00:00,  5.03s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "rFfe_71fgGRT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#text2text_generator = pipeline()\n",
        "fix_spelling = pipeline(\"text2text-generation\",model=\"/content/drive/MyDrive/models/bart-base-spelling-en-repro\")"
      ],
      "metadata": {
        "id": "kH0IINDDgE0f"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(fix_spelling(\"dood\"))\n",
        "print(fix_spelling(\"i cn not lern ths leson \"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FoK7bVyQgHTO",
        "outputId": "7017adcc-e69c-4e15-b6b6-7f9407e7ab62"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'generated_text': 'Good'}]\n",
            "[{'generated_text': 'I can not learn this lesson !'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "from transformers import BartForConditionalGeneration, BartTokenizer\n",
        "\n",
        "# Log in to your Hugging Face account\n",
        "notebook_login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "d25b9a7726b947f59f7b350dad3c15c7",
            "5f2f899da2ff4adbb707678ec53c48bf",
            "ef40607288114d4b858197b888101010",
            "a00b7daf426946f39ae8963067ff7c4b",
            "19c3c7197f5648b9bc687d5ce730d47d",
            "5d628ba5c86f4c1ea8ae17946faa3eb1",
            "d6091c1a8f9e41dea0c18725c044f61f",
            "e9e8dcf59b4443b1ab70202917dd8cb3",
            "3cad1abc33984a2f8981a15d607673bd",
            "8ac3a6a55da846f9b82bff5ad5785c89",
            "65750e9ea21149dc852ff87270b289ad",
            "c40d3e151e5047799f20a82c78917190",
            "ed531e03af9647eda148558c51b7c502",
            "8c4dc26ab85347cf981b64db0dd1c265",
            "53f05e89538548a8b02df80c06f9c936",
            "fff90ae9cbd4432d8d9616f793d72cdd",
            "47c65ddfcd3b4ea1bea3c8c766bf071b",
            "7661ab9caeea4ba880bd38171abfbad1",
            "da6cb343da4d44259e6d1a19c8fada73",
            "331542720ed143bab3c88b2853a2a2d7",
            "fa6af60aa8e4499fae6317fae3c50d23",
            "a12db16086a54e77afeba35ec47cc94d",
            "32a97647e2fc4f3ea0da79212f635fb7",
            "d11f6ad4735541859cbc54dc758d0617",
            "b0786bd5639a4734bcbe397c5e324d54",
            "6fc53aa0b97c4f378e8638570e8c9845",
            "d55b683fea114661aef8d2550babddb4",
            "9b2fffeccdd440f2b1ba6906f4635edf",
            "74da0b79a5d44aeab35cb3f48ae231e6",
            "8bc3b53341c348fca0592017904e390e",
            "f1740583a97140ee8094b580ed7bfbb8",
            "735003783cae4389af10e959338b976d"
          ]
        },
        "id": "x6GR4BY8tylE",
        "outputId": "dd0892bb-17d6-431c-df90-6b9cbac872f0"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d25b9a7726b947f59f7b350dad3c15c7"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your fine-tuned BART model\n",
        "model = BartForConditionalGeneration.from_pretrained(\"/content/drive/MyDrive/models/bart-base-spelling-en-repro\")\n",
        "\n",
        "# Initialize the tokenizer with the paths to the tokenizer files\n",
        "tokenizer = BartTokenizer.from_pretrained(\"/content/drive/MyDrive/models/bart-base-spelling-en-repro\")\n",
        "\n",
        "# Push your model to the Hugging Face model hub\n",
        "model.push_to_hub(\"spelling\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138,
          "referenced_widgets": [
            "18f1a5e9a31e4b4c9d835bf96899c38f",
            "e280f109f8d3478f92e91f23cc8f668d",
            "aa41ce9b9e514b01be08ad864d56b8f8",
            "480e70de3645430d9957807bc0a64789",
            "11fcd25f9b45490dabdc8e9b889ff511",
            "6224ee2ab1194e9f936656417ba48f65",
            "074dab0f43984fb59a761d0d48f93e19",
            "3497e925c7b3417d9d8f15eb5ef1c28b",
            "d17ea8fa6a9147ae8f49faa39d7746bd",
            "882966b68dba469d84d77ccc5bbc490d",
            "d40f90da4e2e41e1aeb3adce4b5ee36d"
          ]
        },
        "id": "crTekkdvwwz8",
        "outputId": "149748a8-283e-4c54-92bf-f6b3681eac21"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/558M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "18f1a5e9a31e4b4c9d835bf96899c38f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/Elalimy/spelling/commit/cb5d1ffa4143eae420274bc26739aa14189a87c7', commit_message='Upload BartForConditionalGeneration', commit_description='', oid='cb5d1ffa4143eae420274bc26739aa14189a87c7', pr_url=None, pr_revision=None, pr_num=None)"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    }
  ]
}